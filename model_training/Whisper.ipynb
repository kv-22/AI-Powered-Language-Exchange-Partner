{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dC6RT3B6GE81",
    "outputId": "ae3cb66f-0c27-4952-ad0d-e9fe3adbba08"
   },
   "outputs": [],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIWYNGOIVHGG",
    "outputId": "3b5b4aca-0e2b-4c56-e872-64fea68a477b"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets transformers accelerate evaluate jiwer tensorboard gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1T6i00G6emw",
    "outputId": "4b7a2590-8d99-42e2-aa0f-c0f70f83746a"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.50.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM9cRZKwE8iu",
    "outputId": "ba02fc75-da63-4979-ed8b-ae04aa1bb168"
   },
   "outputs": [],
   "source": [
    "!pip list | grep numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A5chAvC7rW2"
   },
   "source": [
    "Make sure numpy 1.26.4 is available else there are conflicting errors due to the imports from audiomentations (for data augmentation). In Colab, after running the above cells, restart the session and then run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bRhyEwLDG2U",
    "outputId": "7dc5cfc4-c3c1-4897-e01d-4dec44be5c0a"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "print(numpy.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qW1_V2mr-1Nh",
    "outputId": "cd1d6757-0bf0-41f9-8fae-7a4c64918b4a"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "74a11c4df5b049e28f1d939c15addea7",
      "869d45ff21db4b049eeae06f4fc8b6e8",
      "8f116f95551e40a18380fb62a974ca51",
      "7028dafeebd34bad84188477ad496411",
      "c7a8cd2d042c4aa9b00756a58dbb6044",
      "6f7893cc75ae4c05bd7cc93cc85b60d6",
      "0d0d5dbf4b6a4a09847ad9ee961795e5",
      "376e6ac4a94443a5a6ca8515d1e7a704",
      "fb46d55464b34ebdbc080fb799c7b2d4",
      "c3b07e77a22c474e955d2802a5f861df",
      "0da171a48e58412d97fc78ff072f9ebb",
      "c468e9ecbfd54d6f917a5050ea049606",
      "1da97dab3d9e436a96cb98779f6e1e36",
      "5f1e5ba66c504673a07741abac809afb",
      "401fca0f48cf482ba91b837b296ab315",
      "568dcdac3b594592a08e8224467adb21",
      "858f1dca3be44ca995e4f8b0fad0fb7d",
      "b35add43ef484008ab2ad88759fc562f",
      "73c1a7c99f8c4bb39e2a9d6405581803",
      "a0e4da6cdac140e28f96592418458ee3"
     ]
    },
    "id": "upPq9QkpVO5x",
    "outputId": "b5b718fa-8b79-4ab4-daf3-85faf1648bfd"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASD_AfXT82wV"
   },
   "source": [
    "**Load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvEkDCFusj6d",
    "outputId": "3b983132-08b1-4782-bbcd-2894c1d0dea2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "c930cc783c244c0b9dd53bfd1f25d850",
      "118214092f684b28baf67aba90074122",
      "08a70f1a11c4482ebd27f44404734ea8",
      "2dd860d3f4bb4fe7a6d1fb70db2d312f",
      "122d10eee20249089e5742629c15c7a6",
      "d5116144790049d49f60df9c3b83e088",
      "1054a642554f4a21956c233c5bac2ac7",
      "dfdff8e576644a299a7f0a634f1df2d7",
      "b9a429442eec481686abe86fd46f69cd",
      "f7d4e3077b3d4768bff99de09afce940",
      "5024ffba86ea498e9dd529eeade6bfee",
      "79f2760125284bc296b6f3206a25f58d",
      "ff497505c66e4c1cb2f9d24f4cab2761",
      "f08c33d49f814c7fb2c3d53e37318795",
      "28a151fbfb4f40c694e70ecce1cae55e",
      "aeeaa3226c5b4cfdb467fc2537c01d6f",
      "552beabb279c47bcb25c277d3647064c",
      "365e9813a5f04437a2a195ba694c2360",
      "07857070c8684bd2b744eeee80cad1cc",
      "c0dc521e59a2407ca527e6f86487e1a1",
      "0c51f6d20d2e4329a49b79ffb282f7b9",
      "e6ab0d2c751f429da328c17f9b2a9523",
      "f3009c173e2143bf9107a5955fc3052e",
      "9f2de0dc650c4e71a4e32eeb251cca95",
      "cf0522b7c1cd4283937e89ec8bfc4fc7",
      "924fb3901e81474da542a60d0304b6de",
      "52a67bdfbefe4156a40f9771ee40be02",
      "7c556eff6cff4740b6cbdb0e99d57058",
      "fed695749867426f94c9d9fe5c89e808",
      "05b44990b3b74852b1fd19bc67b18df3",
      "34dfe068a6b44fadb5798f111c97b73d",
      "e94275bd4d144e7d8ace350960d8c0ee",
      "ab17a3316c9b4455b5322dc313a2a0cd"
     ]
    },
    "id": "FwhC8fw087Na",
    "outputId": "3ea2dbd2-47d1-4d78-c9fa-6bc7aa305952"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"/content/drive/My Drive/dataset_new\", split='train')\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qniZ9G0T_Kmj"
   },
   "source": [
    "**Preprocessing and EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_xwpnU6c4IC"
   },
   "outputs": [],
   "source": [
    "# Get column names to identify the second column\n",
    "column_names = my_dataset[\"train\"].column_names\n",
    "second_column = column_names[1]\n",
    "second_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmDC4crNGp8z"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvrY0L8LHuZl"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PM7b686LIlIY"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have both eng and arabic\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[A-Za-z]', dataset['transcription'][i]) and re.search(r'[\\u0600-\\u06FF]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset3 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pJNBr94MOrO"
   },
   "source": [
    "Checking whether the tokenizer can handle the english text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "78e3c27cee5b4b7488d5311ee0a7a0d3",
      "15d0593cdaf849ca839510b6abfb696c",
      "a4ec6aaeb84545a1b8c5584bb526b635",
      "f9b0db8081e1470098b6b448ed50d840",
      "3fe1c44c58c14b63a23c7334627755df",
      "2b34f514620b4333b2b0f3a1752019dc",
      "8407160354494d61beb809d0703571f2",
      "482de078d9614802ae88843c0eb0175c",
      "3d48ee0c8c7e45c9ba0ffc594a645794",
      "4051b7c8fc8b4201ad26b25237494297",
      "d717f2aa0ede423596085e09a22ba4de",
      "f1c719bf7561475482ae28be7bb4e4e8",
      "eeccc715de634e31a1fdd26f397b09e9",
      "94de17e4af554f32a9c98e7dca4d924e",
      "c021c1c5499c4dd8afd9b1e2a9694d82",
      "96efb0e9acfd403f8f927aee103167a7",
      "7bfb732bef3b474bbd3d418edbc2dc0a",
      "c55790b2b11b4d93ac97980eae795ab2",
      "1a7cfed36c42415094235b57fa0dc721",
      "f09c2ccebff5412c8da15e04942e7ab8",
      "1ab3012295124ee89edef51740d67665",
      "f47deca87cd34b249f2399abc147fa12",
      "460bbf5d843c4643a9e7ffb4b17ff189",
      "68b83c52338d4e16a197d0fdfe3e7be1",
      "d933f06d149b461394c9c8b9590df0a8",
      "3983aac0c4bf4350a4937a8be7c706e0",
      "f625f9cae7f348cfb25ff50cbfece47f",
      "ac18d096254d474f83d83a375d77a53c",
      "1bf137f1c29845469f19f1c3e460a3d6",
      "f1d6bdb5e17348138ddb551859f1ee21",
      "aad05962bc6a4b0cb3c2dc43c2450c6e",
      "044a5d9ae812420fa3dfb5a6529c7dde",
      "8cd1a058956948b9a7f8d5c93d49c9e2",
      "e47082732d6041818a531fc4c73e1d70",
      "6b22a926aab04b2c9305aacb18ff21f9",
      "60fcfc4cf2c84966a5bfe2b723f2a455",
      "9dabdb8f1ae44f9691c25bda486c9348",
      "506728beaa2e427caa6183a8ff76021f",
      "b37a10d800ee4fe7be39c99a9baf4f96",
      "1cecbe4ac797430bb12f86a3ff536f93",
      "cf61be1266f54aa7bd3e9fcbc6249fef",
      "728112402b0f46b39f3dfd276ccec51f",
      "a617e911861e4c09926524f8c8aea115",
      "22c178f7ed584505be22a6efc1b84450",
      "ab2bda277f6f4647bf25236fdfe3d363",
      "17297f6c8f4845c69283f3f34f4e2153",
      "8e0e8c6170a14f1286f8627d4b9c5364",
      "4c1a991ac30a44d3b92ecbe4924d4a4a",
      "d7083fa38c6149ca8b546cdf1bb0a18c",
      "5db7126c69de4e7591764485e08966c6",
      "33e7f6df53f847bda87518b2f3906f50",
      "c1c054b95df94982abeca09bf056a08c",
      "3d612eb16da7497298eb320b2aad9c9b",
      "22199c2025da47e28de8192ee3b72602",
      "00f1b39858b4410ba9686c6e002d0ec4",
      "fadb85654fea4a3c8c53148d24ccb5d7",
      "fa498296eb7e4293b6233060fc5eea06",
      "22cff4d2ccd1458b96f3b2aaeb46d2d6",
      "a8830630c7bf46eea2d071c514c590be",
      "93da6022bf1a43148fb654b9a5edacc8",
      "74bfe8f172d54d2b9c42150aadd733e7",
      "a7c04f8c913b4b1ebb19d430246d3913",
      "143e1509a4e5408caa15f92c65fd50e8",
      "36375cd034d14144a089c80d8b8af9fd",
      "5244e43199764d62ae36d6fa6b9035f9",
      "7df4ca7dca6e41f489ffcc3f47c4032c",
      "d35112e103eb4cdaa3657c00b4e04b77",
      "43fd4f9067504d528dc448792e20a162",
      "4a4eab18cb624015a30989fb85d2cd82",
      "364161e3435e4be291192474f6ea4da2",
      "1959898297ae44abbe830fe21644a5ac",
      "d0cf437501b945048229ecfcd8c34e8c",
      "91eec9633f51469facdb4e29a54a55e3",
      "f0c8685e7d7f425985fe53a7da37876d",
      "12abbc739462446f99e13c1c64100ed9",
      "357c3d8da746400da65712b2f260b344",
      "aa6da38e99b84642b6692bd31c697d0f"
     ]
    },
    "id": "H2L-DTbILiRX",
    "outputId": "66a4641b-11c4-4ccb-a884-230797dc3618"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNZUliyFLlpa"
   },
   "outputs": [],
   "source": [
    "input_str = filtered_dataset3[2][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "print(labels)\n",
    "print(tokenizer.tokenize(input_str))\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1rkZvuOMew2"
   },
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ifC9O9ev6Yk",
    "outputId": "aceed833-4fdb-432a-82ad-57cee550ac94"
   },
   "outputs": [],
   "source": [
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-uAUtrPvxnu"
   },
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "\n",
    "before_filter=\"هو أننا فقط أخذنا وقت طويل جداً بالتفكير بالماضي حيناً وبالمستقبل حيناً آخر في نفس الفترة الزمنية وراح الحاضر بدون ما نحس هذا بالضبط اللي خلينا نفقد التركيز ويسمح للقلق والتوتر بالسيطرة على عقولنا وأفكارنا وهنا تجي فائدة اللي يقظه الذهنية اللي تساعدنا على تجنب هذا التأثير السلبي\"\n",
    "after_filter = araby.strip_diacritics(before_filter)\n",
    "print(before_filter)\n",
    "print(after_filter)\n",
    "print(before_filter==after_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "433464d4a3024935af767d99692cfa4b",
      "3ecd47ea824042e6a276898c3467586f",
      "dd6147e7a864486f92d06e92951ba611",
      "6dba945fcc1442f3ae82782890d88f6a",
      "311417545c0047d2b892731e1adf6da7",
      "55a49c3a042e41cbb7d0c434c67a9a73",
      "9a3905a2d18d4892b95b721f9ed51665",
      "b9782894b78248e8abfefb254ef5e682",
      "c0abb4bd16354333a0d4347a4b277a1f",
      "bb9e52a32f3341529a90dfed8d8347dc",
      "eacf3e49a5f34a6baa4e72541c20bcf5"
     ]
    },
    "id": "Gtkxqbd7WJlb",
    "outputId": "a44bfaa3-a68b-4c33-de37-268fae03fa75"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "# remove punctuation etc\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[.?،\\-؟]', '', text)\n",
    "\n",
    "def clean_text(example):\n",
    "    example['transcription'] = remove_punctuation(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "532f995c18f04bb3a5a243da557ee51e",
      "33bc4efcd4544e538e1e7d9ab9c9928c",
      "d89f05c03fad458a86dc6060f7a21e2b",
      "e29408d9a3b34b1d8ba02de6ed7a5d04",
      "32838c1247434811ba335b2e36f7b2c7",
      "b0d67a2d216a472097c5ad3d181d97e4",
      "7026c708a0194d4ca17ac74d7f84bf36",
      "c72b31f8937c45c2b81c0d5620330c7e",
      "82553117a70643a280fba4f76ade0661",
      "038b2b5b36c748d0a8700ab978627a1a",
      "69fc4305e5b74c4f946e4cdd6181235b"
     ]
    },
    "id": "2qLuhX0qAWsm",
    "outputId": "681606c3-a837-4e8d-9edc-58ed7fb9d277"
   },
   "outputs": [],
   "source": [
    "# remove diacritic\n",
    "def remove_diacritic(example):\n",
    "    example['transcription'] = araby.strip_diacritics(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(remove_diacritic)\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EiAuwJbX1ag",
    "outputId": "a13c523e-55a6-4baf-8083-cb884ff580f9"
   },
   "outputs": [],
   "source": [
    "# check if removed\n",
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)\n",
    "\n",
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRqBrdKUv25D"
   },
   "source": [
    "Hear some audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFzAJp99v25D",
    "outputId": "a042a941-a464-4fb8-e205-d535136b108a"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(my_dataset['train'])-1)\n",
    "print(my_dataset['train'][rand_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "cyOuSQfcv25D",
    "outputId": "8dfe028a-2379-4680-e906-14f3d8d53dde"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "print(my_dataset['train'][rand_int][\"transcription\"])\n",
    "ipd.Audio(data=my_dataset['train'][rand_int][\"audio\"][\"array\"], autoplay=True, rate=my_dataset['train'][rand_int][\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ_xQ7gq-ik9"
   },
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VYPESo2WLBY",
    "outputId": "db97265a-871b-4bb9-b870-edf2154cfd2e"
   },
   "outputs": [],
   "source": [
    "# split the dataset for testing n validation\n",
    "\n",
    "my_dataset = my_dataset[\"train\"].train_test_split(test_size=0.3, seed=42)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZY-GjZqtr9v3",
    "outputId": "4bf796c6-9b7b-4fc2-ef54-2497b04d732f"
   },
   "outputs": [],
   "source": [
    "my_dataset_test = my_dataset['test'].train_test_split(test_size=0.5, seed=42)\n",
    "print(my_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ea-DWjzsIJi",
    "outputId": "b428be6b-b259-469a-d194-d341d1ec3304"
   },
   "outputs": [],
   "source": [
    "my_dataset['validation'] = my_dataset_test['train']\n",
    "my_dataset['test'] = my_dataset_test['test']\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "8NlGGO089fxQ",
    "outputId": "f63d0d48-dfd4-4fda-fb7b-5c18cd57f36e"
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences and calculate their lengths to find max length\n",
    "# tokenized_lengths = [len(tokenizer.encode(sentence)) for sentence in my_dataset['validation']['transcription']]\n",
    "\n",
    "# print(\"Tokenized Lengths of Sentences:\", tokenized_lengths)\n",
    "\n",
    "# import numpy as np\n",
    "# print(\"Mean Length:\", np.mean(tokenized_lengths))\n",
    "# print(\"Max Length:\", np.max(tokenized_lengths))\n",
    "\n",
    "# # x = np.where(np.array(tokenized_lengths) > 250)\n",
    "# # print(len(x[0]))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(tokenized_lengths)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbemXMDq6TNk"
   },
   "outputs": [],
   "source": [
    "# test_set = []\n",
    "# for i in range(len(my_dataset['test'])):\n",
    "#   x = {}\n",
    "#   x['file'] = my_dataset['test'][i]['audio']['path']\n",
    "#   x['transcription'] = my_dataset['test'][i]['transcription']\n",
    "#   test_set.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnkc58zATKUT"
   },
   "outputs": [],
   "source": [
    "# with open('test-whisper.txt', 'w') as f:\n",
    "#   for item in test_set:\n",
    "#     f.write(f\"{item['file']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbPiiWIk-x1I"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "84507f00b81f46bab8ac8b37c8b4cb65",
      "daf75dcd07a148f2a2cd0813db108d5a",
      "a050b14e0f75461a9589b4e0ed937da9",
      "26d602acc81c4912b9eb01c3c99a15d4",
      "d57a61b502f749e4b87bb9499beba6c0",
      "4d582123861d4a0aab13d8408dcadb56",
      "b7f2a3be26e8452f9e7e50f4c8221b6c",
      "b8ca46e83c194776b59740909111458f",
      "765cd7157a6a49f29817e079a20d968b",
      "41043720547345d19dc631bfcda79414",
      "29715dc914b842908f812788d5466eff"
     ]
    },
    "id": "ISfgygpHa38i",
    "outputId": "e5029e7e-0fd7-4f09-f3f1-bb4faedd59ea"
   },
   "outputs": [],
   "source": [
    "# input to whisper should be log-mel, this is done automatically by the whisper feature extractor\n",
    "# it also performs padding and truncation\n",
    "\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "e45e44515be34c8a89427fc231fca09a",
      "f0b9a133628943d9a8a3c89f8f52514d",
      "db33ecf976794110b0ba345720e5a09b",
      "871e604830134c88a3a9cde96631d5be",
      "13b29e04beae42eeb22cb342e690773a",
      "15f401c7ba7b4c1099bf1767ecf0363c",
      "2f07c975364b48eebaf47e0cf1d6a1a3",
      "77af3bf44a614d878aad2db6dffb516f",
      "c7b73ac035aa4f2a875ad548b7f8047e",
      "d8a4968761834438b91dc7b8a223d6da",
      "eaf798ca182b40588fffb50bfe9e8cb6",
      "35d76657980344d9b9b05e177642abc7",
      "58e10bf909414a0486aee53870a5d5d3",
      "9568dd7ad13c4dcdb4619a596dcb7f06",
      "bd26a41a95a944ccabef716fa8e38c2e",
      "b50965823dcf4545be0a6af6fe079484",
      "d265a0946aaa446299cb8c6eb7dce11e",
      "6accc327618b4d5b88c2792702f81fdc",
      "38cdb15c5a63478eaaeebab652f6ba8a",
      "304965a481d84558b8e957bbf732f313",
      "cef6e2990a9544088520be1bcf587a74",
      "33c91626ec2245b28a03de7549b6d06c",
      "bd443800c14b448095c1a23145a5d62c",
      "c04937f15768446ea459af636c2cd710",
      "455b799326c44ca69056b71ed3614d6e",
      "8b917449115c4ccb8716fbd0d0913d20",
      "ce5022b14b7c4a55b21a6ae639d8bcfe",
      "dc6b5dd40aa44acc8ff7de3ebd59b5b6",
      "34592966cb2e4d28b2ee5cc65ecdad27",
      "43a4843a474743ffb1bef91824636036",
      "6dbd10ae85e342ebb912e06edede044e",
      "6a91c970e91d43cdb9c03a0eb841ae26",
      "fec29fbd42d147728972d0afa5770ca7",
      "7310b070085145a7b815b55f396da22a",
      "69d204b916fe422ca0ca9feb78f362d4",
      "8f148f3e03c740d4a1d9bbc8f7805cfd",
      "ef3e464a7f2944febc331c237b0dcbb8",
      "e2bd9bb5f8534f1e883b4c5ced43f10a",
      "22c8bb497de444ff9ebc769d4c9689e6",
      "37db842b7f4a46c086fc0c1fa4f63972",
      "44622ebfbc104f8b877d17a32480e2ce",
      "f306f88522324ddf8a4d07fb67057820",
      "87d25ad556cf47b7a9eaf22d8cca7a2b",
      "fbea66eeb81c4ec08feb76b3ebb96c14",
      "67db0c1338334fb0ae2489f8cb405ce8",
      "afee457a5933443d84ae620f20eff77c",
      "5ed180675f68416dab627fdfde803900",
      "edebb960e94141f3a7c78494a138b39d",
      "84201e89a2584d25b029bb06667cbd7e",
      "6ec98734f98342e69fd40704c6cf24d4",
      "17dd6c92f1c649a890db9356654cdffa",
      "eacf584080c74fcca850e0f0ed660d70",
      "f4d4eb74e6c94b4ebcdb2c8bd8c3730e",
      "486b3c07e0a541ea8a85f608fa70e5e3",
      "915a134906654d54ae724d1d81c44e25",
      "90d89d3b5c9f4e558581d83d09af8ae2",
      "af0eea60e00043b883782ff738c05fcc",
      "e94c96cceddb442298769d723f59e6c0",
      "5c3ab1766279409b855758ec51bb730b",
      "584611c07cdd41999d8e7bdd2f2ae941",
      "ce14921fad1a4dbe974c789c95f2e90d",
      "aef04e0454174544a9d3ac1afbbcaab5",
      "f5a600cbb0c84538976414760bf4256b",
      "f879fd2a102f4380bbdeddfc06aa41cf",
      "9fcaa1a821e14b6383b90ce6b3611b9a",
      "e34a2a67cae34efb90c1a91654f4d121",
      "4688103ec3cd4fcb920fca01e6ca136b",
      "856954b7dcb54db8a4b1df1f761e801a",
      "441ade965ecb42af8961fd0fdb56678b",
      "e0d9090922e94f2bbaefb6eaebc7eebd",
      "3a9240aa20314e2b8c37c97f2c346187",
      "12fc4ba852fe4a6dbce26faf6b925406",
      "d059d25ced174183a9a0119ada14df6a",
      "32e3873344bf4003b8f341a95e9c4717",
      "55c0cc251930413cb2db9356ab50bc6a",
      "686de97f7f254787b76ceef2a88e468e",
      "29528428b96046138520f49b6ed18127"
     ]
    },
    "id": "MfbQW1VsdxcS",
    "outputId": "13f705bb-c677-4f86-ecb4-729198ceab34"
   },
   "outputs": [],
   "source": [
    "# load the whisper tokenizer to convert map the indices predicted by model to text\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "811tGIy_fFDv",
    "outputId": "117bf6a4-2fc8-41e0-9fec-3602560c5084"
   },
   "outputs": [],
   "source": [
    "input_str = my_dataset[\"train\"][0][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFpGhaMYfsQP"
   },
   "outputs": [],
   "source": [
    "# can combine the tokenizer and feature extractor into one object\n",
    "\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFHUNiC6gMpz",
    "outputId": "49f6114c-972f-4b68-c003-35eff9064179"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl5bbjkqgTxf"
   },
   "outputs": [],
   "source": [
    "# need to sample the audio to match whisper's sampling rate, this does it on the fly when audio is loaded\n",
    "\n",
    "from datasets import Audio\n",
    "\n",
    "my_dataset = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQNbzBPheHd",
    "outputId": "20103942-ef07-4e1a-dc01-b8f6b51f04e8"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyc3ckpi-1s8"
   },
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "58a082bae5424199ab975e991df0fab4",
      "8a8c5ba2439f4b778e2456702d7592bd",
      "8ee99c7301bc4411b08caa090f9bae32",
      "325fea81609c4de0a457c0937510894d",
      "4cb7295bb3124c389cfb58bb575f96d9",
      "4d9fde20ccbe4c689b9503e33afbfb00",
      "b4f0965ababb4a63b8ad1455060da0fe",
      "d1970e4f1d9a4a248a66803c55b63a0c",
      "876f6996539f488b8a87f280ccf5c8e7",
      "21200a506a254d838fe89005795f92d6",
      "748ecd347a984cc89723f8ed57ecf76e"
     ]
    },
    "id": "mbiL8Ctty2Om",
    "outputId": "bb92d2fd-30fb-41b9-9c91-73bdef867b32"
   },
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, Gain\n",
    "\n",
    "augment_waveform = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=0.2), # add gausian noise with 20% probability\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.2), # change pitch with 20% probability\n",
    "    Gain(min_gain_db=-6, max_gain_db=6, p=0.1), # change volume level with 10% probability\n",
    "    ])\n",
    "\n",
    "def augment_dataset(batch):\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    augmented_audio = augment_waveform(samples=audio, sample_rate=16000)\n",
    "    batch[\"audio\"][\"array\"] = augmented_audio\n",
    "    return batch\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(augment_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuTiEyvf-9Uj"
   },
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10H8ZZXuhgVq"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0] # its a batch\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "4d228e3674e24d28af90b32e0ae20f32",
      "1cec7bb6765e47e79885ee7b0f7f2062",
      "ec6666ac8c824bd58484c38f94a38e86",
      "d1d61f51eda34cd68aa4d04f22d3f054",
      "72ec34c8a65a4200b277169ec3032450",
      "ce7b22281ca04831bb65a85eff54835f",
      "44033480c12e49f6afe0ea9efb65f6b1",
      "b962c3159ecf4e8ea702f192e506df5f",
      "8ea65cef6b2b4f6995a8ad072c2ca267",
      "0428fc0477bd4d159e2a0eceaf915b86",
      "7e4201489eb24eb08a3e6a770b98fa5b",
      "9a50e06cdbd84198bb6a86a0688c23d5",
      "fdc8a08c82b84dd282d7c5d7a3353569",
      "af2eb13ec77943719d4772edec03001a",
      "7f1b21bc6bf9422bbc809b9bf5017108",
      "4857f6511b0e4ed591e369d4956efb50",
      "baf88ca850a34da7a59faf03a524dd05",
      "4e769b6734cb41f38b71a197c0410136",
      "cfc22941cd2f4c3ea5539f8fc4a121a5",
      "e510ed9ef1844883b770fef9cbcf6cec",
      "68da7ce9a3734a16acf3c890f252b3b3",
      "f6f712884a13412c8f78b39754b2be5d",
      "cabaf4e795ea438bb96fc178c2aee505",
      "cee8851f3e984047b6ef27c23f4eb37c",
      "3931de2d04264de49d11477d3461cd06",
      "849b705f2ef744ceb4d9e136434ec37a",
      "3f1ba11c285d4b378fd96c2a3f3f0f72",
      "b70c2c527bd342f8b2105c7e5c866779",
      "a2999beb594e430584168427b4ce0bf4",
      "37bc4bcdece640e9888d7e4b98299be4",
      "89968e3f007c462094e3671008def219",
      "0b2ea9e428224f31b0b14855ec89c3d6",
      "9d3360343aac4deaa4faebfb16285a7d"
     ]
    },
    "id": "Hi4uCFqOCUGh",
    "outputId": "43976014-882e-468b-a1e2-7343878dc5e3"
   },
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.map(prepare_dataset, remove_columns=my_dataset.column_names[\"train\"], num_proc=4) # use num_proc=4 to make it process faster, if gives error remove it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-ONe_m0_P3P"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "d7d59794dbba4edbac41033e01a141be",
      "14f37e144f3d44b39852894cb96f64f4",
      "0bf1aed02a87401c957002212db783e0",
      "389992dce8ec47bead129600a4c259b1",
      "39144e1c1e39418b9c60840d1ee4da02",
      "e7dc296c581d4afeabd94c41c61e230a",
      "c2717ff041f94ce682d45917192f4546",
      "d173ff2640934841b2d9525208701bb2",
      "9c072f1dc2924f03893a5c60791d544d",
      "ab622b3cbde74df89316161a83f40d57",
      "e22230a233fa4f838b2093d008679061",
      "e94498b5aa5441c5bf27166601071c10",
      "12f733f4f6df4b13862a0ef9e474d0ba",
      "09c7032f3543442698b29cc43a294004",
      "c91f8bfa29ae4c9fb1bc83fd84deee8d",
      "8ac82c104e314241b6d00d6801c3a740",
      "cf7f4299988944d38aa3985535be1774",
      "53e1f6833f39497885b9830124f57e9a",
      "ef3a5489ebc3483fa8a5cd0119e24531",
      "88805d93f56a43d197d0bd5c2e2e6614",
      "e34efe459e1a43bfbb17995ee4b19bba",
      "16cb429a4e88472c80110c1e1ac535f4",
      "3b5845de21c74562ace2e8731ee840a0",
      "eee236be5009448881153ee017dc4511",
      "658a3358ca5e47ef93c4f30187f991d8",
      "5fcb5f94c7e249e4896126ff805f5b46",
      "477e9909067b42bd9affa9faf4e4806b",
      "3ee266041ff74e639fe583d716523ce6",
      "dc4ede02a8754b2fbafc202526caca80",
      "885491f4ec384ff6aeba171a9dc92039",
      "4ac04f85871d40469a34d9027ea9801a",
      "28bce4cd6ace4ddb88202edde904e732",
      "f012381301f44dae9b5101ebb7c6b061"
     ]
    },
    "id": "jcnMTDyuDLu8",
    "outputId": "6542523e-1a28-4190-edcf-af6034635fac"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLwavWMf_tz6"
   },
   "outputs": [],
   "source": [
    "# tokens in transcript can't be more than 448\n",
    "\n",
    "max_label_length = model.config.max_length\n",
    "def is_labels_in_length_range(labels):\n",
    "    return len(labels) < max_label_length\n",
    "\n",
    "my_dataset = my_dataset.filter(is_labels_in_length_range, num_proc=4, input_columns=[\"labels\"])\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vn9y46BbD8N6"
   },
   "outputs": [],
   "source": [
    "model.generation_config.language = \"Arabic\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None # don't use the legacy method instead use the config above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PS6l5pxFpwz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass #decorator that provides init function\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\") # pad the input audio and return tensors\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\") # pad the transcript and return tensors\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100) #ne not equal to 1, means get padding tokens from attention mask and replace with -100 so the loss function can ignore them\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rWkWp7nOYi8"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a79799ef3bba439fadad6190d1512af8",
      "7fe931dbda034afd92058085aeb73548",
      "01a1da52e3e844e59366dbe17db038a2",
      "694f3e94d2b3493e8f4b9b19b90ba3c7",
      "80be16a24ee64db3b43f8c2ccffeddb7",
      "fcdd32b0d75e4f7ca9502c3aa714b7f0",
      "93b882a1a88a401aaa0b45fe8b3f1313",
      "fce89783d56448d8ab81946d7b646818",
      "0d68fa5318204b61829a0f019c9f86a5",
      "e34898ee00494ce19df908c4433c8d25",
      "8fa1a575cdf3479d8f1bd974f8d67298",
      "6ab3f62c804d4b578e14c95cc5feaa9d",
      "8b008a9e6150481685d33dfd2317c286",
      "1aabc70617214949aa972c093a3fabd2",
      "cdf514ea854e4590806f8bea64d456dd",
      "6d95bdef44024e90b93bac09f9e7be16",
      "5ea9eea64e2a400f9885f2335ab272ed",
      "c3b30da3c73a4861abb7510afd292c90",
      "7f396a4d47794fd19f8a3cac32181a8f",
      "b4e7fe7d793d4c5a8f88d6760805c1a0",
      "1937310eaedc4d7eb023a0bd6d001cd0",
      "62ac92958b2f40309608318a23c11e20"
     ]
    },
    "id": "pXUKE-PXObhp",
    "outputId": "b8c4deda-e094-44a6-addf-a16be603b916"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "metric2 = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZKsFgspOyt7"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True) # use batch decode to get literal tokens for calculating error\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    with open('refs_and_preds.txt', 'w') as f:\n",
    "      for ref, pred in zip(label_str, pred_str):\n",
    "          f.write(f\"Ref: {ref}\\n\")\n",
    "          f.write(f\"Pred: {pred}\\n\\n\")\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = 100 * metric2.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\":cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYsZ7bRpcSWQ"
   },
   "outputs": [],
   "source": [
    "# model.config.dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuxjJc1fRZZ-",
    "outputId": "1da958a8-9b20-4128-dded-26e8994dcd7b"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"\",  # change small if diff checkpoint\n",
    "    per_device_train_batch_size=2, # this can be reduced if out of memory\n",
    "    gradient_accumulation_steps=8,  # increase by 2x for every 2x decrease in batch size, accumulate gradients before updating weights when using big batch size to help w memory\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=250, # for lr\n",
    "    max_steps=2500, # train for max steps\n",
    "    gradient_checkpointing=True, # keep subset of activatons in fp n calculate again in bp for memory\n",
    "    fp16=True, # mixed preciison training with 16 bits instead of 32 for faster training n memory\n",
    "    evaluation_strategy=\"steps\", # steps not epoch\n",
    "    per_device_eval_batch_size=2,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=270, # tokens\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False, # because lower wer is better\n",
    "    hub_private_repo=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9Cletk8RaPy",
    "outputId": "5275ae7f-abbd-4245-e613-c7661da95d79"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=my_dataset[\"train\"],\n",
    "    eval_dataset=my_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    callbacks=[EarlyStoppingCallback(2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "5qtVU-ysRl1i",
    "outputId": "e471832c-2124-4133-ee7b-45746797967c"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "referenced_widgets": [
      "8547d461d8e849aab5f74982de53d86c",
      "5337f9493b7d46fdaa926d32d357f786",
      "1408f452b0784ec68ac78c0d30f715a2",
      "e4b9431eaaf34c43a765a4819b958ddb",
      "ae86c3c19363422d967243f6c51beef2",
      "df54f192a8f04fdb9ad42fec264ec396",
      "31ec9293dacb4de18df7ffdeadae2d62",
      "563fdef51c0d41aeb4f88c435f90b802",
      "be454b2895e44866b8d65942ab868144",
      "e0e68e93284c475c8521f253ee7acfcc",
      "ac43d54e98ff4fee8d8821adc83ceff4",
      "74fad778f33542bfa20794a4608fbbfd",
      "27e11a6f04b342a08f586fdfa2e126ec",
      "a3f2078b0c3248768285c6f99e2f771e",
      "9ce95a5dd66c4e789fda0dcc874504b4",
      "5f1d418c8f124ac2a45d539bded78afa",
      "0472582423594400aac7d6406cad7468",
      "5826c2ea781c457ab233f8e7ecd903e8",
      "55503a6ea35f47eca5716677dc3ec12a",
      "0a91aff9a6c54549b3ea422f3ddbc199",
      "89e0218f45784ca6b83be42db54a2990",
      "0f0ab19d3725445ca33400ff41cae3ac",
      "4eeedb892d8a49738484cb64bd7b2b22",
      "ee4de905e4e241e4b01a3a6cc5ffa335",
      "19c0bf4496b34f9d8810e817bdfdb626",
      "e06677985db444bfaf717fc3a2ea35a4",
      "79f9a0569edd48ee8fc80aea4501a51c",
      "8b580a9c3a5641ea8702112f2cd092e8",
      "d9ce14e7e55e4822a6915084bf4004ce",
      "a6d2e9f46f8b454fafbc1cee6df36f19",
      "0bcfc0e235c940d3914be2fbc41708be",
      "e8ba160042644e45bdbe21d3674f26ec",
      "cf9363563d5145a18304d38be9d7e528",
      "52eba139bb8f44a3b01981e554bec4af",
      "a4c5721a46d2431ea3641812620885ed",
      "69e7e719e4bc44f5ab58f24a4f767b95",
      "06ec1bf4fdaa490281066f1d05b156e0",
      "e615de6aba654f22a143e6b8ab72527e",
      "12296c9cf0cd4aef8395beab871f39e5",
      "cc5598fcc12b4584ab84da7743ce5bef",
      "82c1215218ce4cd592eecee1ebbcd5c2",
      "9666a59a1cca418885589b0cd87de618",
      "95115327b3e645fe964f1b03ce883bfe",
      "03af25d84e5840f2bcc1ea3f195fd0aa",
      "25083b801e494c6099dc42342656f717",
      "e0de9ebc893649e580e2766b2999d06d",
      "0ef9dbc121924d3c96f5af694a61f72e",
      "0101074fc59843268b85d0d09f834d64",
      "c31b246684564935b5782107a8b2d3db",
      "47803d4a5c544aa5880ff19ff5b7a91d",
      "68d46c0084db4253967644fe909524da",
      "7b5bc94f16e3468e96f468fe75918619",
      "db749ceaf02c42688cc12fd50ca11596",
      "0e2bf71d90cf4106ba514bfc03479ff3",
      "a9f1fc671edd4ee181df4c3d3ebca092"
     ]
    },
    "id": "9Y5fqvCbbH6H",
    "outputId": "9d088f27-7c75-4e59-a3a3-eeceb4652a08"
   },
   "outputs": [],
   "source": [
    "# write meta data\n",
    "kwargs = {\n",
    "    \"dataset\": \"Informal Arabic\",\n",
    "    \"language\": [\"ar\"],\n",
    "    \"model_name\": \"Whisper Large Informal Arabic\",\n",
    "    \"finetuned_from\": \"openai/whisper-large\",\n",
    "    \"tags\": [\"automatic-speech-recognition\", \"arabic\"],\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "7a9649288c5c41e9a83b6e52678e4483",
      "631766271bba46e88fb0dc07fe2fbf09",
      "f8327e359013451ea33e1cd9b8c6b31d",
      "795d80d755ac44a18fcd5d2fa88b911f",
      "18a0880ba5fc448ab951d6ed9d648024",
      "37433a0e07ab47cab8d9fba087ec63e9",
      "38ff2800eb024a16b370de7350506b26",
      "da2479eb23034b1e8004905c1b7f9066",
      "c722e2a7e2344615af26a80ee95cc944",
      "a72c8b337ad54a5ab17be2c455011a21",
      "6cdf2206f5a9480e8168b74271d6ce31"
     ]
    },
    "id": "LkTJmv_ZCSpt",
    "outputId": "473a8c55-7efc-4007-de80-bcbbfb187331"
   },
   "outputs": [],
   "source": [
    "repo_name = \"\" # should be same as what was defined when saving model above\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGZdE0zBiGYS"
   },
   "source": [
    "References:\n",
    "\n",
    "-https://huggingface.co/blog/fine-tune-whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXRJ54x9_lhK"
   },
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610,
     "referenced_widgets": [
      "0bc9aac74d914c0fae06b31b0316d619",
      "8a702f30ac1a41fb928e0bb092361d9d",
      "c2ba36d2e1f04e1a8bfe72268cb67590",
      "a2708f5b215b4dd2b6258630e1227e83",
      "d74f720829fc41169a6e1cc55cec63ab",
      "b4aa55c4b21949a1ad9ba40c4db6a7ab",
      "6730c251f022405ea474c1456dc5f958",
      "a5c5ebfd1f394236a69f920215d1509a",
      "175391a6ab164959a60806ca3c5c5196",
      "babf6d14b5ee48e9a54ccde0e1411c03",
      "20d1dc28d9ec4a90a3a9ab62024cd94c",
      "c3f6f7517c28473da2544c1cce53c756",
      "e2fb35fbbe734a23bacfaf1b86b6f87d",
      "fe48ad99a9b04340ad408e4967fb8840",
      "452de66abe84405ba4109e8db10fdbad",
      "cf5c1bc4cb21419c8a4ab8712b1027fe",
      "393dc3036d704179ae22e02e20a7d073",
      "7ff8f4a18cc34cf8839579215b1b0f66",
      "7007043065ef4e338358a32064349135",
      "2d4edc41a7cf4732a5950fa3f68697fa",
      "b10029812fec49bab916bd947151a493",
      "64688f31b81c479d9cc8f7b63fe14b6d",
      "44af9861c9834b5496b9a5f9a5baf1c2",
      "c02dabddce7e4d56a2343b0dc6501524",
      "409874277432427897b3b031fd82440d",
      "7e00ecd5cda34ea99733e916669b7d4b",
      "ac4bcbf01d8b4bbaa3af9f841e4fb950",
      "ba438e2fd92848309d94b35422228ab4",
      "26c1bd87e6734c46a8c96637db4b0e76",
      "a8ffcb372be4447ba5fc3589577e27e4",
      "be9895a9819c4c799958c0305612a604",
      "446ac1a343d242b1a876e62224fc3628",
      "405df54b558043d2975410e381101502",
      "9641dec36d0a4ad3b06bfe974e352c6d",
      "7abfae4daeff4b46af590cb2e939d45e",
      "dd627d371240495c8dafb2fec8a7cb1f",
      "24f23824543d41279b07434793e918e5",
      "983a005f0ffb4c638fcb5aeacb134c95",
      "4dc7d626effb4aa699f952bd440da922",
      "0f57e8dea4974d10aaa8ab8ef297add5",
      "929cea7b85a84dde80f19c0d2b171781",
      "5876185da9df4e709f5d4a5c1fd62bcd",
      "13dfbf50859c49dda8b1c1e577dbbf8a",
      "fe66f64ac9844c2da3da80de54c1c208",
      "731c2e435d5c4aeab1e6e4d5e593ccb6",
      "8fde49c9868646b7ac4ef0a026373bdc",
      "5ade877457b646a3b5a2ad4e37093d1d",
      "788cf530f52949229690596514dfc010",
      "cccf94f87a7e4742a7c9aa36a7601d59",
      "5e817b27a7c04bc4b7358e802ff2a25a",
      "f21d1285bd724c9b94e9743f05f4a832",
      "863ae9ca40024a81a85e631025fe0dd0",
      "e269ebb1c8914e418ffc774b6134f396",
      "0a40261f69aa4bb7a812f4a78ac54298",
      "16ceb1aa031c4ca7af992eaf72701b06",
      "3470826f30f649e887f8aa7d66fc3a46",
      "82748968b9664ae5bdf8a73606d88eca",
      "cdd5f5c0c727415ea6efa5423d986504",
      "f4b8e08dc67246c49f19baf5d9a16af9",
      "75d778c058124fa7b414e298561cbf78",
      "7f564a11227b4decbb63892913b14e1b",
      "8c5c96e360934f5ba3fd3f0375eb261d",
      "24341845157d4741accc041c1120de8a",
      "f0e5be365dbb4838babaa359b65268ae",
      "c5fbf0f8df5e4da38a98e7c5072aa243",
      "31210efc08a24a789d2c2ac891a057b8",
      "f57061c881194d3fbdfe79746ab2405d",
      "681b24005b5b46569be39362c4841a93",
      "4ff112855fd3498b9acf0ca9296b9f1d",
      "4595565b0ac94c138780739197859602",
      "ec3a406f74284c23a2cb1bf6a0c95c01",
      "44f1e07f3a064c11abb0310853b7b178",
      "b9f7171b07c1449793d48473a8aa545d",
      "72c43733ab05471585a96b3abdf7d0b0",
      "13987dad242743be9080ff15094e23e2",
      "1e738b1d4b5c4caca86a0ac4bfd0717d",
      "22f688e760a74d1bafb465f2241b7afc",
      "72becdb6574e48059a7bd9bb64985247",
      "5aa72fc1b1cf4080b0ca1432d01abc9b",
      "7fc254ee6cef4e34b5de3af8497e5171",
      "4649467a93f5427bb07937ab05a8c640",
      "cb77de9ed38c4839b23ee5868fe3cb67",
      "87f5cff03c41420ca437882aeaf46066",
      "24ec40a1b76b4fccb4ebee92dd02a8a9",
      "5abd3d1a0acb4b2fb9d736fe30b88c08",
      "23b5a26c96234527805996e3c4776bd3",
      "5447dfa0375e466399f2ca3cd942852a",
      "e2653a597b9a47718b466af8ca5d4dd0",
      "387bd16bafeb44bf8be3c11f6e2b8e4f",
      "b1c3bfa010204705ba93b03935beab2d",
      "c70df2a300e44269a4caa41e11dc9ef6",
      "a6d64f7d79974cb2adabff5056c0334d",
      "fa2c286828474772a263cea32bcbc708",
      "61a991855d8d4fcc941b2ef57c8f3656",
      "b0e4cd6a3b8a4240b9fa0502e5760a39",
      "9741a1aceb144052afd87c4f37392fbe",
      "00fed926a79b4fd3b69da667755c4f77",
      "dcd4d159dc4b4051bfcd8a50542ba654",
      "b708fc7d33a549eb811e446301a3d1a0",
      "da2f7840c40f41e1adbdea81363b8444",
      "57b597acb23240118510a94ae2e950e0",
      "12488a2bce0d4280b34f6a6a165c527e",
      "f1bd6f7f3cf04e1996e3a8a0a3ca5547",
      "6bc371fb7d0a45e1bced9b233e8cb0e3",
      "11c6a0d0c579435599fc2fdaf9415a07",
      "835499a1b4184160977756532dec185b",
      "f247be0456824d249df359fb437bd16a",
      "dc5d9d80ac5e4989954f727556eadf2e",
      "a5d5407db41c4d8ab4987f94ce1ec926",
      "72bd96d1203f45b39de0d0ffbb43d5e4",
      "9fd2d98492824edaaaeeeebb821fe9e2",
      "70557cb9342e4edcb7ce7867b50e67ea",
      "9572a357117845e5b5b637954de1c58b",
      "d65240bad825460cb8cb7d788ca0c453",
      "1b0f0cd545da433ca206472b347ca963",
      "beae09627ba0447da173c2462b7ddb11",
      "6e73096dfba5449e87c1d371f512ee26",
      "7f933b3e2e294b26a1562730bdac2857",
      "ab7ea0d05b0e48ea89336e316bac7784",
      "b65668c9dfe84fa7bbc05ad7e831409f",
      "79dc2a57fd274effbabdfa58f9c72b29",
      "8a931837948d4ad0be52bca3ca3cfcae",
      "28c83c1f29e14baaaded30300e58f8ca",
      "6950f19677df49d6ad19beb800d35017",
      "cf00d75bfeb3411d81584e37fbca3f5d",
      "0d85c771b8f64910a42af7e09788cfef",
      "79a0b29915e440ad9f5b03906b6ecfec",
      "d6ea982a03124a139fd7136db04077d7",
      "621f1f3c7aad48ab85681e0f10b88b99",
      "bb9b412c3b1c488c9d453ff6612214d5",
      "501ba67256ba493a85077ddcbfc0ffd5",
      "e5117c2200264378aaea4b503344dfb9",
      "f8b65b41e68c42dcbc68c7bc71c7eef6",
      "1601355e5cd442fe964f5ea64e4a0664",
      "a980d00dda5b40e28285e2098da664a1",
      "8f85bf9eb5a948aeaa3778d809ce1f96",
      "4566cb9a306e44d98a2c20fd1466b5f6",
      "3acd6a90b5bd450a858e31f4559dc518",
      "060f876000cb44c0ba025392c7d353bf",
      "6d3b6106d33c4defb986ba3bc6c576c0",
      "95cf8d29cef244bfb5ff06fedf8d2c65",
      "da92c32241aa4892b9cc3b63d46ea809",
      "2dcee223876e4a1fbd45c5ffe0d56f1a",
      "bb9bd3439efb4d24bc96c07763d8e5be",
      "46407e052c1a4be3a4bd5f6e475b7fcd",
      "69037f1e270a44bebadcaa4fd7d05b13",
      "ae8a39312bb34dc4881b039d5d075f44",
      "fc2b3709e8a3401d89074c88a316de8e",
      "3cd9800076a242e2a161f21dcb6e69a1",
      "50aedc21c62942c194f7740c0db2f31a",
      "22d03ddbb4a44a4bac191e5e1e4129e2",
      "20af4514ecbe4f59bf692af96a641e30",
      "a8f254ec616a456f87b51318ee6ca4f5",
      "4d6e9a1dcb01466abbf2fadb25a94cf4"
     ]
    },
    "id": "GHFgi0hGpzvv",
    "outputId": "a2dec8dc-afeb-40b8-acf0-3327d3f4bd18"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"itskavya/whisper-large-informal-arabic-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eMg7UKYITEy",
    "outputId": "cb0f0692-0b44-4113-f3fd-21f2aae6e990"
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "\n",
    "for i in range(len(my_dataset['test'])):\n",
    "  transcript = pipe(my_dataset['test'][i]['audio']['path'])\n",
    "  all_predictions.append(transcript['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "8d1a3e3f678e4bfebe80b468aadcb68b",
      "7fb2469a0bed404c8392208908b938fd",
      "8503d958a5da4af8a3ef288a2968c044",
      "a9d7265f637947d98402ca727781d996",
      "43e5406c99a24d0e8009cb962e9c6cec",
      "68e3430b43e3467db467e422b03ba6f0",
      "fc807a0f18bc469bb6abe9226f3600f0",
      "caca2773dbb54d1c9c2dc5e3caf034f3",
      "1fd6c70e9a3642688b2009304e9a4104",
      "c0ec9e148d594f788a49157a6ab602e4",
      "d473dec6207f45db848abd96a4231d79"
     ]
    },
    "id": "5YXxa_jOGPCT",
    "outputId": "9c9e3106-a00c-4bf0-a8fb-0631a892c402"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "wer = 100 * wer_metric.compute(references=my_dataset['test'][\"transcription\"], predictions=all_predictions)\n",
    "wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "813139e8e7774561b68422953ed2425f",
      "4001732122a14b3db017db671cd72046",
      "bc48e8c36b2642fb856b42a8f47b3d72",
      "1a53bcf5dc2a48ad97d19e79cbc98159",
      "7c955e2c9e904757a22b27c4d46d1813",
      "95c76281cce74e79bfb025910cb6acf3",
      "7433438ccc284eed9d00f8bfcf157e9e",
      "7a9008f60c02481ab45af6c77b7f7fcb",
      "dd78576da2754c66a44fe2c9055144e4",
      "6267a4a59c8d4de1816acad65622d192",
      "897b8a2fecdd40679c398bfd8e7f8a5e"
     ]
    },
    "id": "Mi_MeavWL_Gy",
    "outputId": "fc143266-2d3c-46e6-ea6a-4b239b13acd6"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "cer_metric = load(\"cer\")\n",
    "\n",
    "cer = 100 * cer_metric.compute(references=my_dataset['test'][\"transcription\"], predictions=all_predictions)\n",
    "cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3nwd5OgOO2N"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('output-whisper.csv', mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write the header if needed\n",
    "    writer.writerow(['Ref', 'Predicted'])\n",
    "\n",
    "    # Write the data\n",
    "    for item1, item2 in zip(my_dataset['test'][\"transcription\"], all_predictions):\n",
    "        writer.writerow([item1, item2])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
