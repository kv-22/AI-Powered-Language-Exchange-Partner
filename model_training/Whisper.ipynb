{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIWYNGOIVHGG",
    "outputId": "7bf20161-696e-4a77-cf6c-6e128a050633"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade \"datasets[audio]\" transformers accelerate evaluate jiwer tensorboard gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "654eb37d535f478dbf40bbaca8cc8286",
      "5351e31020be47a297cb4d51f2641fad",
      "97444e6fd5ba4932bee34bf8a9df8136",
      "47d1adf731064b30aaa467d75f0cd740",
      "fe4d6033af5a46ab9331143b0bb3dafb",
      "dc3256f6b22d440a81836fbf05a13a0c",
      "7d021f342b2142a4b65ac016526bb95d",
      "a33541376f804b8d84304e6326d2e9f6",
      "468baa1f76f94fbfbe596468127304ba",
      "744d13744d0a4e378bc0a096a9a496ae",
      "0f6fb4aa0e1644939735966df4b46289",
      "7a84f9906a8143d3962186c05cc3bcd1",
      "5a39bca0d2b6446b89da5062be9534b7",
      "6e0d3ff5e0bc44359a58c60b59f0a27b",
      "992c22917625430182e0a146ad8865bb",
      "d0efcae7d4a74637807948f700da9d71",
      "182a273674f34905b394cde4314d0212",
      "b9fab366f7364bf8beb445fee6c94a28",
      "57ee6bafffab43d6ada75cb3bc79c8d5",
      "95c3604898b0414c9cf3143628171f39"
     ]
    },
    "id": "upPq9QkpVO5x",
    "outputId": "7a283cf8-e36d-428b-8c52-99acfc0c1d6f"
   },
   "outputs": [],
   "source": [
    "# generate a token from your hf account n use it so the model can be saved to the hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASD_AfXT82wV"
   },
   "source": [
    "Run this only in colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvEkDCFusj6d",
    "outputId": "82ac67bd-20d5-428e-892f-2e878611ae7b"
   },
   "outputs": [],
   "source": [
    "# download the \"dataset\" folder from onedrive and put this \"dataset\" folder in your google drive once, then use it because downloading from hf takes time on colab only\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')  # Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "19b096554ef8476480cf94e4426c3bb4",
      "995d4786cf12450884eae4d486409112",
      "80ebd6ec56554698b3b06e558b60f868",
      "f62892990e0f4050ac847c3a43ad1a92",
      "5521b8384a45475fa83448f8759bdf40",
      "4333df2b9a1a4e019f80d9308b8fea9f",
      "8d9b1d223d684126a42af4234d872d82",
      "c06eb96efe3e47c09e66769c6eca6c15",
      "b9ced51de8ee49df8287e03e6f076440",
      "8adbecee88804ad8a3f7205c71025f39",
      "30d19445f8164d219e211fe12ce50f89"
     ]
    },
    "id": "FwhC8fw087Na",
    "outputId": "547f0ed6-04fe-486e-f88f-8b40432e580b"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"/content/drive/My Drive/dataset\", split='train') # USE THIS ON COLAB\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63hNqf508-qL"
   },
   "source": [
    "Run this on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0M0dlNDV8uF"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"itskavya/gp\", split='train') # USE THIS ON YOUR MACHINE\n",
    "print(my_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qniZ9G0T_Kmj"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "p_xwpnU6c4IC",
    "outputId": "4ccc72d8-4aec-4dcb-a0a5-3b67c4daccc0"
   },
   "outputs": [],
   "source": [
    "# Get column names to identify the second column\n",
    "column_names = my_dataset[\"train\"].column_names\n",
    "second_column = column_names[1]  # Get the second column name\n",
    "second_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCUZDpkJ7m6w",
    "outputId": "b74cc9db-0cd3-4b79-9f46-120bc68f8af3"
   },
   "outputs": [],
   "source": [
    "# filter out rows containing '[موسيقى]'\n",
    "\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if '[موسيقى]' not in dataset['transcription'][i]:\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset)\n",
    "\n",
    "my_dataset['train'] = filtered_dataset\n",
    "\n",
    "print(my_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmDC4crNGp8z",
    "outputId": "64d26bf9-78af-4247-8429-f358d6ee8805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvrY0L8LHuZl",
    "outputId": "30f0b030-992f-41af-c568-ce1db3f73389"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PM7b686LIlIY",
    "outputId": "fa2af213-1542-42ab-c8d5-aabc7f133b44"
   },
   "outputs": [],
   "source": [
    "# filter rows that have both eng and arabic\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[A-Za-z]', dataset['transcription'][i]) and re.search(r'[\\u0600-\\u06FF]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset3 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0slfAu_KuEs",
    "outputId": "ae7b1c7a-808a-4f84-fca5-814c867dbaa4"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset3)):\n",
    "  print(filtered_dataset3[i]['audio']['path'])\n",
    "  print(filtered_dataset3[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pJNBr94MOrO"
   },
   "source": [
    "Checking whether the tokenizer can handle the english text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "a47a1806cc1e4069b32b3f5807c4f10f",
      "0ecb54305e634d109d93dc70f929408e",
      "dbe80675f7584754b6a88659dcd469db",
      "3fc9cc86829c40f6ac8105c992a0960a",
      "de264a0969d2460b89573e0cacc06019",
      "1046e0e49436450f8fcaac2e53963b1b",
      "51ad427476774c3ea643dc128786489c",
      "94ef943a6f0d496c80945ef8fa8303c0",
      "e0a7dafeb64c4e50b7dc7871eb7ecde8",
      "90e74106b5714db4835a24cd71b7b588",
      "2b41e109061e4d1498a39d98dc33bd0f",
      "efaf79b1416040479c30a365dbc5fc6b",
      "4c59e0e927c34307b7b6f059f9976489",
      "c6424d4a27d14fcc921bd6232549e390",
      "45546017890542d9b35ab2455819e1fb",
      "445dec5761624e99a49912b7bb5b9eaa",
      "7ea09060485c46dfb1e6f29ac22b5051",
      "c703054a5c13402bbe6593050d5b4993",
      "d24e4dd061cd4cc89cd247885ea97e03",
      "dfbbfeef342440698ca955482e259b95",
      "58f0082f45374c53b34ffef4efcc8b37",
      "2160891bde8f4a1e93b80989874ec398",
      "3219414e8cbb449998107afc02b3993b",
      "21e17eecd398496b8b96f08163647046",
      "f666f1eed9434060a2f600ba18bdb2d4",
      "6fc482d2a9b14fb6ba662ec31a928faf",
      "9a24155bc99149a4be5df4bcc028b631",
      "1df07dfdce3f4871bf85090616974984",
      "8caed7dfda624849805a65cd6ebeb4df",
      "ef3915b8503240eea3a345d69178eec3",
      "6317ecb3a96f4674869eb0eec2c9d56c",
      "186dcbc8f5ec49cf91a8b3f1c2d7bcd5",
      "3c898676f12e4e87b9f30c9c47416f6d",
      "47092846ab19418686f550ad84c3edb3",
      "c39205ed565a4117b301aa8ee1a97a6a",
      "83fcf4595778445eb71f66b539f50c1b",
      "fcf8c3d94c7943f2ab27b5dad951c137",
      "e85af645ed134b779c639d7b41042309",
      "e53345a5821e4d8d8e0e5b150683220d",
      "7c60b8b440974a989f8acb66ea4ef7b5",
      "53092af0dad04beab973b887e4d5d431",
      "8d242c7789be418bab79b8c6ba599805",
      "475e688225be40f89f4ec1c5a91d34e9",
      "083cd6c9aa5c4ddeac9d24d9a3234222",
      "9fe45399ab3941d790627b9f1c0183ff",
      "c7337af2f2e9480989505717ff51d299",
      "8d83fb2c3e4940518352d14538c3c9a1",
      "7e101a3f46724c5d8da1a4a68aba61d0",
      "a4d408ebef244293a3cce2da88061de3",
      "e9fe4626ed054788ba69d06551052a1a",
      "44fe468a73f046d2bec014401c49d00b",
      "b3c19d8513d74704a73f23ee1d64c54d",
      "7d04e1689bb34381ac08e624fc852b9c",
      "e347cc996f0040fdb74a7a84c997df1a",
      "d64918bd70804ac8861ca86ad1887dcc",
      "85d2c56ffdcb492d979080bdbc2fe456",
      "f68a4ae588f841dcbbfcf0070eda99ad",
      "87948be0d9bd4b3f91dd3dc28454a715",
      "94881122ba9441d78dbea545fa6e4954",
      "56917549f7b14c25860afb7df0aff6ac",
      "536ae4d357ad41c4bac068b78e9c6786",
      "1f9d6da4f4e744f5902d3081ab79ce11",
      "3a68da90115d4e638bde29633105c226",
      "c15c9dee33d6478cb9c0ee1c7c685042",
      "dcfe47c52ca84a49825ab5abab09cc40",
      "34d13082efb242ad8535e669baf6b084",
      "0f57b25843874aaf81a76ed0fca4aaf2",
      "9254958c12a64bf5a022e8e0209a49cf",
      "824f6f9a9e024f2ca6c855d726273c5f",
      "f81cef4539e4480f9d5b3441915e6fae",
      "38c3bff120024acea95172d2dc274215",
      "0ed831799a6d4ce59c39338be6dae4ba",
      "47e0a272c9844bb28a9c8d32e405bf10",
      "c38b1fbc2db24aeca015dc251731200b",
      "eac915860c054adb8d016039c860e442",
      "02f4493a1f824a91a7b004b083b6a00d",
      "cd0164f8db314c118ed935e208ea25b1"
     ]
    },
    "id": "H2L-DTbILiRX",
    "outputId": "2d5e2c53-d047-4ef6-fb5e-1a84e10f22fd"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNZUliyFLlpa",
    "outputId": "b96b4cb8-33ab-4ef4-8765-9eaa8207ac6c"
   },
   "outputs": [],
   "source": [
    "input_str = filtered_dataset3[2][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "print(labels)\n",
    "print(tokenizer.tokenize(input_str))\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ifC9O9ev6Yk",
    "outputId": "93c52f70-72d5-47da-93a2-e0d33ae06307"
   },
   "outputs": [],
   "source": [
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-uAUtrPvxnu",
    "outputId": "e9bda7c0-399c-4fe7-94b0-ad38f6a8dcf0"
   },
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "\n",
    "before_filter=\"هو أننا فقط أخذنا وقت طويل جداً بالتفكير بالماضي حيناً وبالمستقبل حيناً آخر في نفس الفترة الزمنية وراح الحاضر بدون ما نحس هذا بالضبط اللي خلينا نفقد التركيز ويسمح للقلق والتوتر بالسيطرة على عقولنا وأفكارنا وهنا تجي فائدة اللي يقظه الذهنية اللي تساعدنا على تجنب هذا التأثير السلبي\"\n",
    "after_filter = araby.strip_diacritics(before_filter)\n",
    "print(before_filter)\n",
    "print(after_filter)\n",
    "print(before_filter==after_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1rkZvuOMew2"
   },
   "source": [
    "So only clean the text as in remove the punctuation and diacritics, the other records are deleted/fixed from the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtkxqbd7WJlb"
   },
   "outputs": [],
   "source": [
    "# remove full stop, comma, question mark\n",
    "def remove_fullstop_and_questionmark(text):\n",
    "    return re.sub(r'[.?،؟]', '', text)\n",
    "\n",
    "def clean_text(example):\n",
    "    example['transcription'] = remove_fullstop_and_questionmark(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qLuhX0qAWsm",
    "outputId": "bd9cc682-8bc8-44e1-99ce-0d233773d36a"
   },
   "outputs": [],
   "source": [
    "# remove diacritic\n",
    "def remove_diacritic(example):\n",
    "    example['transcription'] = araby.strip_diacritics(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(remove_diacritic)\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EiAuwJbX1ag",
    "outputId": "dd0df213-c7f3-4b2c-d18e-fa241b883ec4"
   },
   "outputs": [],
   "source": [
    "# check if removed\n",
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)\n",
    "\n",
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRqBrdKUv25D"
   },
   "source": [
    "Hear some audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFzAJp99v25D",
    "outputId": "38bfa808-44ec-4eb1-bf62-638327ad0940"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(my_dataset['train'])-1)\n",
    "print(my_dataset['train'][rand_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "cyOuSQfcv25D",
    "outputId": "89a0fa9d-6cc5-4be7-a3c6-1ad013fd1957"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "print(my_dataset['train'][rand_int][\"transcription\"])\n",
    "ipd.Audio(data=my_dataset['train'][rand_int][\"audio\"][\"array\"], autoplay=True, rate=my_dataset['train'][rand_int][\"audio\"][\"sampling_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VYPESo2WLBY",
    "outputId": "6bd0960f-d842-43c8-f8ad-25224ca39acb"
   },
   "outputs": [],
   "source": [
    "# split the dataset for testing\n",
    "split_dataset = my_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WujybCNVZomN",
    "outputId": "75eee8fd-5b85-4e25-8185-dc3c39f03f96"
   },
   "outputs": [],
   "source": [
    "my_dataset['train'] = split_dataset['train']\n",
    "my_dataset['test'] = split_dataset['test']\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISfgygpHa38i",
    "outputId": "457a297d-89f0-483d-b3d0-73efc83b53b7"
   },
   "outputs": [],
   "source": [
    "# input to whisper should be log-mel, this is done automatically by the whisper feature extractor\n",
    "# it also performs padding and truncation\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfbQW1VsdxcS"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the whisper tokenizer to convert map the indices predicted by model to text\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"Arabic\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "811tGIy_fFDv",
    "outputId": "36c57d6e-d1fe-4fdc-f8a2-ac0c4007c0a5"
   },
   "outputs": [],
   "source": [
    "input_str = my_dataset[\"train\"][0][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFpGhaMYfsQP"
   },
   "outputs": [],
   "source": [
    "# can combine the tokenizer and feature extractor into one object\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"Arabic\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFHUNiC6gMpz",
    "outputId": "13de95d4-3485-43e2-fa72-6ceba04c8ed7"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl5bbjkqgTxf"
   },
   "outputs": [],
   "source": [
    "# need to sample the audio to match whisper's sampling rate, this does it on the fly when audio is loaded\n",
    "from datasets import Audio\n",
    "\n",
    "my_dataset = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQNbzBPheHd",
    "outputId": "95507404-eb31-4625-e2f5-c8bcc46e9fe4"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10H8ZZXuhgVq"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0] # its a batch\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ce6c2324ed2f4f06b4f08b985cd5282f",
      "0826966623694cb7a8d4c80f44ce901d",
      "6537ecbf09dd4832af244113bdd97e0d",
      "16daf87631544895884397c150c018f0",
      "57574ae9d52b4377b2f1ee4520f6ebf3",
      "7a45bf7908e8486ea05daaf6dc22fb58",
      "81efd40dc1924bc8b10cf389af74006d",
      "c45d3f306cfd4d60bb79b156f9e38d17",
      "1bd675a9f0ec400c80cb02ca88bc15fa",
      "967623859c2b46af9ed929d44ac45903",
      "c432e8543f7c4ca0ad12969a587c92c1",
      "8a2e4df93458401dba1fe4b8a56e6b5a",
      "40afa47bff9a485bbbd77d3481dd7d1d",
      "05f2353afd514bfeb5e11f14c2111243",
      "1d8c344182344732aca10f941049b46a",
      "f6ac814f50054c8ab7e386fd4f573eed",
      "ff3e8853294a4bc3af5120e9134fb6bb",
      "7fd48c30d6ab43f682e383175c6aa20d",
      "1b958f981e3d4380a1d7c18b36391435",
      "2fbc24c8ac2d432eaef7ff7826956444",
      "c9c6ea3064974ab9a721ecfb7b7647c8",
      "791de896cf9240098fe11d1741db544b"
     ]
    },
    "id": "Hi4uCFqOCUGh",
    "outputId": "022f8983-c911-4cff-e2c7-881e680cf237"
   },
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.map(prepare_dataset, remove_columns=my_dataset.column_names[\"train\"], num_proc=4) # use num_proc=4 to make it process faster, if gives error remove it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "fcd985833dff45f291a08860a96771f3",
      "f6e314c614744e0fafc54b74f18c58f0",
      "7a9552bf63a740b9bb7c2d8f03ec001e",
      "d62f42d81b3e4000a568dfb169c6f3e5",
      "50249a7e402e4bd58dc2ed4dd5e14fbe",
      "a07513b00f6f45a28558d98d26f32d8b",
      "6afd101f8cd446408333ff002451a209",
      "2221f2782bd54d5184ca8bffe00469d6",
      "245bdc3bfb0144548b4a24180fa74634",
      "40826b51d3ac434c8c00cff5075bfc44",
      "cbd31acb4c77469c9d52826329b6a5a5",
      "f163553bb4a34e92a92a12676d969757",
      "a5680849265d497ebc145e5cebc2f601",
      "f77811f659444a4080d155a1b0929327",
      "56f2723c81e94d4c9599e9a506e3ac71",
      "e9758372e2934162beee7972c931edf2",
      "5a27c02667fd46aea0705330c0449965",
      "c55b39575c4a46ea971600365ff58583",
      "47497d870a374d60b549fc106daf025a",
      "e072d604b0d84451bd46086d030a1564",
      "c128a1b2bc074b38922408435a8278e5",
      "c4873805ffb8451080181ca3a88bb6b9",
      "6efc691e32194433ab8b6eae54615bec",
      "d848e3f168f146eeac5cae800446b0f4",
      "c2826af380de48cb9d18526a68ed95e4",
      "4d9f907e5ed94526b0017c9e64c10093",
      "55556abaad4040adb400c7c0b8525f75",
      "4734e1c7f6264ad2a2d9a16ca61e3c98",
      "1910e7e595914a58b9571746631e45de",
      "bd11a618ce7a4d2d9221122369b581ae",
      "b4154ea759f34b2e9b4c7d1ff82aa5a9",
      "d7eeba1d9db445239314d0c83c9913e4",
      "c3a03860938f4c99b8d7709347f0220c"
     ]
    },
    "id": "jcnMTDyuDLu8",
    "outputId": "0f72b0b4-c757-43d6-d261-3db5732144d7"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLwavWMf_tz6"
   },
   "outputs": [],
   "source": [
    "# tokens in transcript can't be more than 448\n",
    "max_label_length = model.config.max_length\n",
    "def is_labels_in_length_range(labels):\n",
    "    return len(labels) < max_label_length\n",
    "\n",
    "my_dataset = my_dataset.filter(is_labels_in_length_range, num_proc=4, input_columns=[\"labels\"])\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vn9y46BbD8N6"
   },
   "outputs": [],
   "source": [
    "model.generation_config.language = \"Arabic\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None # don't use the legacy method instead use the config above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PS6l5pxFpwz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass #decorator that provides init function\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\") # pad the input audio and return tensors\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\") # pad the transcript and return tensors\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100) #ne not equal to 1, means get padding tokens from attention mask and replace with -100 so the loss function can ignore them\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rWkWp7nOYi8"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXUKE-PXObhp"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZKsFgspOyt7"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True) # use batch decode to get literal tokens for calculating error\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuxjJc1fRZZ-",
    "outputId": "5fc98e4f-5de8-4dec-acb5-5e9d12412a59"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-medium-informal-arabic\",  # change small if diff checkpoint\n",
    "    per_device_train_batch_size=16, # this can be reduced if out of memory\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size, accumulate gradients before updating weights when using big batch size to help w memory\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500, # for lr\n",
    "    max_steps=3000, # train for max 5000 steps\n",
    "    gradient_checkpointing=True, # keep subset of activatons in fp n calculate again in bp for memory\n",
    "    fp16=True, # mixed preciison training with 16 bits instead of 32 for faster training n memory\n",
    "    evaluation_strategy=\"steps\", # steps not epoch\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225, # tokens\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False, # because lower wer is better\n",
    "    push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9Cletk8RaPy",
    "outputId": "0f803e36-2e63-4da8-b97b-9181802e665c"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=my_dataset[\"train\"],\n",
    "    eval_dataset=my_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "5qtVU-ysRl1i",
    "outputId": "c47b5a94-8961-409e-d6d1-87edda0c17de"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "9Y5fqvCbbH6H",
    "outputId": "be1c4964-3120-4896-8d33-8501ca1eac5f"
   },
   "outputs": [],
   "source": [
    "# write meta data\n",
    "kwargs = {\n",
    "    \"dataset_tags\": \"itskavya/gp\",\n",
    "    \"dataset\": \"Informal Arabic\",\n",
    "    \"language\": [\"ar\"],\n",
    "    \"model_name\": \"Whisper Medium Informal Arabic\",\n",
    "    \"finetuned_from\": \"openai/whisper-medium\", # should be changed if we use diff checkpoint\n",
    "    \"tags\": [\"automatic-speech-recognition\", \"arabic\"],\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaNo6bGvbJz3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGZdE0zBiGYS"
   },
   "source": [
    "References:\n",
    "\n",
    "-https://huggingface.co/blog/fine-tune-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cA5R9N5iHY6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
