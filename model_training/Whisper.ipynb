{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dC6RT3B6GE81",
    "outputId": "40c851fb-1e86-4bfd-b5c4-ea6b5d89bba2"
   },
   "outputs": [],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIWYNGOIVHGG",
    "outputId": "fa50f38a-4321-4333-a8fe-468b3a69e157"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets transformers accelerate evaluate jiwer tensorboard gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BM9cRZKwE8iu",
    "outputId": "8ad08333-d8c9-480f-c909-703bf57db8f3"
   },
   "outputs": [],
   "source": [
    "!pip list | grep numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A5chAvC7rW2"
   },
   "source": [
    "Make sure numpy 1.26.4 is available else there are conflicting errors due to the imports from audiomentations (for data augmentation). In Colab, after running the above cells, restart the session and then run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bRhyEwLDG2U",
    "outputId": "edff32a1-54e5-4cc5-8fa0-130113a332a0"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "print(numpy.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "3f75975917ea4867951f8ae5cc79cb0c",
      "6ea05b42e35a4c09a1e176eb3167d7de",
      "134364fbc63e44d99cef3ae1d42366fc",
      "9352308aa44f44cc95d55c7d870d51d8",
      "434a64dc50684e5c96aa79236737e74b",
      "0749a58abe4749bf87f6b2bcf091dd67",
      "d8e95e7f63b14831b4d581775fc13d6b",
      "962de64cc23d4cb5b374b1514726094b",
      "4a70d27126124e2196c13d63104cc4ad",
      "b910f8c2463d45a9ad71e7044a3f3152",
      "61ffc4fa35f8407499b981e94b3cd638",
      "32394609c2a94efc924826d741fb77ae",
      "1821171df6da4b51bd005fde23d25728",
      "d44b1f9ccae045e18f04039b3b9cfddb",
      "5bf269629def4d0cb741f24eef2d2e01",
      "5b98fd5b2e0244c2a43648d89ebedf09",
      "ee7b39b4f98c4d9fbc83179caa691b94",
      "6816e649e6fe4c7bb4c20ccc23147854",
      "06f2c41f2a954837ba14bb07db0d2cb4",
      "61e2dfdf32fc4fda982203466a9403ac"
     ]
    },
    "id": "upPq9QkpVO5x",
    "outputId": "784204fd-4c4c-413f-f05b-9ca08a405733"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASD_AfXT82wV"
   },
   "source": [
    "**Load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvEkDCFusj6d",
    "outputId": "de91b4b0-d8b4-4d1b-e2a3-b3ae057c028d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "924649026e7d497fa8eae5e3ee97cc00",
      "5d41aec8e56b41f4ac79d03f3c4bd31e",
      "2d2e62a1f9e14d59ae56583056e7ef56",
      "fe4a3c808d8d48ebbc64ab783f7dace5",
      "29b22eef17e74b99a6ba9fc296701c0b",
      "080e784ec2c3435f8a1195658f9b4e68",
      "bbb9e5f758c146dc8d0128ef5eb24470",
      "8ec0b0182c2845288e29f413686d7a91",
      "8cff69582e9840c5ad13873789f9e390",
      "0ec3139c04864d6a8a3247ac9e741d2d",
      "befa90cb7ae046d69a32d8303b6e7d34",
      "5d03a3cf397149bc836ee6d9bd9e3a4e",
      "39170657332a4f7ea659e0f6290f2aac",
      "2fdb32442bf1443fb24ae17b15306448",
      "e512d72cc7dc45a38d7f7c90614d707a",
      "80851a2244d84c57b86dbc80f73b365e",
      "0a78958bbc2b449b931308209d82b489",
      "5928dda3f0434d4fa071404f0f4b6493",
      "a1816f0918504d97b1af24b4307d8c99",
      "b4188c4eee2341e4ac7a445e90b3aae4",
      "f82a32316c7f4974b91bedfb2da98c17",
      "ca0bf5801f4d41509eaa45de7ac3f280",
      "1e5779beb17b4ca6bcd2292e5bee9cc3",
      "5a08cb03c0534acd9765634869f14bd8",
      "9c43dd7c74d141fcb2be774db476f085",
      "8dedbe05cfbe4c4189f424fb47befb1d",
      "7c6d4d77613e4c349f84cb89f6504633",
      "72be40e0c010462487d8479d2a4fd19c",
      "98bd6894e1f345faab26b7e0c447a8b7",
      "51c18f182def44a6b94cc7efc13e3d8a",
      "3a22612bcbfe46cdb72988ed798d6bfe",
      "02f0e3b3d4fc4bfdbd0dd7362d4da96c",
      "44cc62d80935478ea0c280cc778ba5d6"
     ]
    },
    "id": "FwhC8fw087Na",
    "outputId": "bd7254a4-d1e7-4ea2-c507-555219508cdc"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"/content/drive/My Drive/dataset_new\", split='train')\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qniZ9G0T_Kmj"
   },
   "source": [
    "**Preprocessing and EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "p_xwpnU6c4IC",
    "outputId": "aae48749-6dc3-4f9b-f7d0-c141a15ce93b"
   },
   "outputs": [],
   "source": [
    "# Get column names to identify the second column\n",
    "column_names = my_dataset[\"train\"].column_names\n",
    "second_column = column_names[1]\n",
    "second_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmDC4crNGp8z",
    "outputId": "f8924437-2ef4-410f-b291-f8efe99efaea"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvrY0L8LHuZl",
    "outputId": "20097bfd-dcd3-4c89-ac03-12bbdc215067"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PM7b686LIlIY",
    "outputId": "88e48431-2ed3-4194-82c6-300222f0d176"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have both eng and arabic\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[A-Za-z]', dataset['transcription'][i]) and re.search(r'[\\u0600-\\u06FF]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset3 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pJNBr94MOrO"
   },
   "source": [
    "Checking whether the tokenizer can handle the english text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "dbb85d1970c34f4abe47b1d216c4b4f0",
      "67e41fe01cce4d2586b7b21102aedd7e",
      "d8c8936f9cd940a9acdbd6658d5f2273",
      "24ca36a1de9b4251ab9fa1647f2c68f7",
      "ccaff005584a45a9ab7e105d0878c08e",
      "ceceaf3f2f52486485cd89e446c0e66a",
      "a36dd3592eba4087889546cf4954d85b",
      "b4c3f5c148d94450827807864c75c9b2",
      "10a86a428d6d4bbc990a2dd8ca4505db",
      "75a325a1d1cb4a94853617118ee4ddb8",
      "3c659f8ddc7c4ea29eedbac5e25c3407",
      "27c78a802f0e480aa96a466af613ebfb",
      "13dbc91fb2c04da7b1998899c651fdd5",
      "54b7f5107bdd4c899abb20faa571fc08",
      "e5b557a35d7b467f8a95a775be7983ff",
      "115f52d26973444ba994c41fe96fd89f",
      "6386ee38f1fd47f087935ed20aff12e4",
      "4a6a51ded58b47cba78e7715ac527af3",
      "1c28297805c5415db7c7e2ca6dff115b",
      "30a7fb9f78b7422ea30f77883d38b321",
      "06b7a513656a422bb90e20975f7b9d76",
      "bd462afa2ce14e0088edb2a62cf17aca",
      "e04a7cb956aa4a31b99b80fe23d05ec9",
      "6941e62516674b25896d7621ecb54825",
      "791ef50bfa1a455ca7aff7ffeb4cc019",
      "dc5e9d03aa7f4756b71461d9dfd77092",
      "cace9f29711b4cc389bd383419f239d4",
      "77b3b9f39bbc4a0f877f00980fb23f22",
      "c8b5742e322a4f54a64daee69bcb7795",
      "28b537a1f5964bcab6be9178591daf9f",
      "bbd5e84506234946b1e9c45c492111db",
      "a684e3eb57304c9facd1b5f7aa88e417",
      "bb282ee736c549608d85c86d5406b2b7",
      "34b2464b10c24a40af432fef033a7aa2",
      "3072ca8f4bfe40598b8f82ca63d43807",
      "857464a688424467a936c8ee16f44e5e",
      "a717adea117a43d9bfe39113e826de6f",
      "963ceadd8f944343b30704b8f03dd527",
      "b64cf9fc83894f13a803d9aff9e0e096",
      "85c9fb7e4a4141d683472b5c647b3c33",
      "66f01051ffeb48af8df3809a5b4f0907",
      "1341e9fd4a6f4877a8f4c2121d06bdfd",
      "6da3f677659940068a251884ced59f9d",
      "ea9979cfd0ba4e3fb17502ff11d3c4f0",
      "2436e7ab55884d45b3abb5f7e41951ab",
      "f3bdf4c76fc34235befa14d1b2aa8cda",
      "05eb867f7cc544419574900f37f79266",
      "ad928f1fd39146a09d55908301ad078a",
      "ed9ba944f5744a66bcd5d354b7499c61",
      "8127d346d43544fca924ed644daec3c9",
      "9cf74486225d456aacc3adf4617e3793",
      "c2df4c6a6ad04f41bc1cadee42bcbaa7",
      "d8119b019106452aa34546ac11de4d39",
      "dec9a6bddc6b474689f67af7d2287b47",
      "12eefe5952984a6288f2e7873c0fd818",
      "bd80f8a5a7374d6ab045b5ee5b8c59ff",
      "d7c0b46c4d334493a74bbbebf8212c11",
      "41a94c4ae58b4276b4e42b8023dc2e76",
      "3b86802872314826bd5c6f28c0df6ec3",
      "a4dab5fd72344181abd8372046752858",
      "4ebeed01b5474d618d72e951dc6b36a1",
      "124dd07f0a5a40b599a8861cec63ead2",
      "2258952e57be4118afb5d21f7697418e",
      "3805460031d04df7a5eda0c07884a6b2",
      "6ca5b46ae9124196969be4143d242ca9",
      "21b9225bb1694ec297215bf9e361f4ad",
      "2c072d104a514971ba2829e110973453",
      "59448dc2e538454b936a1b8ba9cb0303",
      "a0e6727d3ed24d05acc7eee5ac5e17d6",
      "b3fa1ee8fdf5411f85fb34e0e9ea949a",
      "562bd54d5cdc42dd93f487bc3ad5bc1a",
      "d6bae2dd2dc540d69a11686f48264da9",
      "0da1ed5af18848bcaaf11642908d0b55",
      "3140051fb0e043e688141bf0cbd072fd",
      "84e9b8ec6c914d349bbbb7cdb5f0ce0d",
      "dffec749003b435b93496163f16d0853",
      "efbc2c4151124cd08bac3c1770216fef"
     ]
    },
    "id": "H2L-DTbILiRX",
    "outputId": "a7c3cf4c-7a62-4216-c689-f843d9754f88"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNZUliyFLlpa",
    "outputId": "f049a5d3-4167-47f4-c00d-640198edc162"
   },
   "outputs": [],
   "source": [
    "input_str = filtered_dataset3[2][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "print(labels)\n",
    "print(tokenizer.tokenize(input_str))\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1rkZvuOMew2"
   },
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ifC9O9ev6Yk",
    "outputId": "1a64a2f8-b3cb-4954-8d1c-faedac511963"
   },
   "outputs": [],
   "source": [
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-uAUtrPvxnu",
    "outputId": "b1a772b0-7213-4ceb-bb81-ee4f34d94fe3"
   },
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "\n",
    "before_filter=\"هو أننا فقط أخذنا وقت طويل جداً بالتفكير بالماضي حيناً وبالمستقبل حيناً آخر في نفس الفترة الزمنية وراح الحاضر بدون ما نحس هذا بالضبط اللي خلينا نفقد التركيز ويسمح للقلق والتوتر بالسيطرة على عقولنا وأفكارنا وهنا تجي فائدة اللي يقظه الذهنية اللي تساعدنا على تجنب هذا التأثير السلبي\"\n",
    "after_filter = araby.strip_diacritics(before_filter)\n",
    "print(before_filter)\n",
    "print(after_filter)\n",
    "print(before_filter==after_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "df05c881564d4329b1a4828c80429ef3",
      "95d32aaedb344b209aab7bc75fb73faf",
      "81857d5d532f4803b9b79990f2d71b4a",
      "592604320ca94aa2a6620733cc79039d",
      "2d2d8b1789d147fc950bad005f2c6c55",
      "8ffe1c28bd0c4380b8bcd5e541bfce37",
      "9b44a77e9a6448c187f2752448cef556",
      "14690b7851ac45c29d72bd816b14c12d",
      "7ea24cb6b36b4b4cbeba59da2a16208f",
      "786736f5427b4e5da25f1781828491fa",
      "3bd583b3b7bc4c4283562358c747d8f4"
     ]
    },
    "id": "Gtkxqbd7WJlb",
    "outputId": "c8e757b3-f8a1-47cf-9c24-ec59168065e2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pyarabic.araby as araby\n",
    "\n",
    "# remove punctuation etc\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[.?،\\-؟]', '', text)\n",
    "\n",
    "def clean_text(example):\n",
    "    example['transcription'] = remove_punctuation(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "67c4b10cf9a54aeba555f5fc8642bba5",
      "40522a95829a44faa59d300fbe43e417",
      "0c0b0a5f296949308bf891f6b5388e46",
      "b7e0637232974a04b44f78c2ae8d0a7d",
      "1b79e94969874b509e72a04b308c18cb",
      "dfc5bf540a264ccd860fdf26816df71f",
      "7c7c0314afd142008158609e0c7a8945",
      "236ac4e22ae64a18adc40ee8b5eb4485",
      "ba9d54b315844d8d82c614c739c67177",
      "d1c6d7b6ebeb4315aee4e7a7d8a4c6b6",
      "14fd66a3bf8c4424a5364eea8d0e5b8b"
     ]
    },
    "id": "2qLuhX0qAWsm",
    "outputId": "a157d3aa-e5c4-4f73-ebf5-99c53c3d7ca2"
   },
   "outputs": [],
   "source": [
    "# remove diacritic\n",
    "def remove_diacritic(example):\n",
    "    example['transcription'] = araby.strip_diacritics(example['transcription'])\n",
    "    return example\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(remove_diacritic)\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EiAuwJbX1ag",
    "outputId": "a76d13e0-0bc8-43cc-a5c3-f99af928cd8d"
   },
   "outputs": [],
   "source": [
    "# check if removed\n",
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)\n",
    "\n",
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRqBrdKUv25D"
   },
   "source": [
    "Hear some audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFzAJp99v25D",
    "outputId": "ce60382d-b879-4808-82b7-97af025000e1"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(my_dataset['train'])-1)\n",
    "print(my_dataset['train'][rand_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "cyOuSQfcv25D",
    "outputId": "7f03ced6-8e91-458b-9b18-1eb593b2d1f6"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "print(my_dataset['train'][rand_int][\"transcription\"])\n",
    "ipd.Audio(data=my_dataset['train'][rand_int][\"audio\"][\"array\"], autoplay=True, rate=my_dataset['train'][rand_int][\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJ_xQ7gq-ik9"
   },
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VYPESo2WLBY",
    "outputId": "d4cb6f43-168b-4ab4-c065-3465b3e4417c"
   },
   "outputs": [],
   "source": [
    "# split the dataset for testing n validation\n",
    "\n",
    "my_dataset = my_dataset[\"train\"].train_test_split(test_size=0.3, seed=42)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZY-GjZqtr9v3",
    "outputId": "bd350c72-744b-484e-c8ba-eab3c529cc88"
   },
   "outputs": [],
   "source": [
    "my_dataset_test = my_dataset['test'].train_test_split(test_size=0.5, seed=42)\n",
    "print(my_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ea-DWjzsIJi",
    "outputId": "a6bc3fde-8558-4239-eaa5-b30074a16126"
   },
   "outputs": [],
   "source": [
    "my_dataset['validation'] = my_dataset_test['train']\n",
    "my_dataset['test'] = my_dataset_test['test']\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "8NlGGO089fxQ",
    "outputId": "20b39b0b-f600-4c6e-da78-b8e4dcdef958"
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences and calculate their lengths to find max length\n",
    "tokenized_lengths = [len(tokenizer.encode(sentence)) for sentence in my_dataset['validation']['transcription']]\n",
    "\n",
    "print(\"Tokenized Lengths of Sentences:\", tokenized_lengths)\n",
    "\n",
    "import numpy as np\n",
    "print(\"Mean Length:\", np.mean(tokenized_lengths))\n",
    "print(\"Max Length:\", np.max(tokenized_lengths))\n",
    "\n",
    "# x = np.where(np.array(tokenized_lengths) > 250)\n",
    "# print(len(x[0]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(tokenized_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyeZiIuqQ1Lr"
   },
   "outputs": [],
   "source": [
    "# saving the audios in val n test set for checking\n",
    "\n",
    "# test_set = []\n",
    "# for i in range(len(my_dataset['validation'])):\n",
    "#   x = {}\n",
    "#   x['file'] = my_dataset['validation'][i]['audio']['path']\n",
    "#   x['transcription'] = my_dataset['validation'][i]['transcription']\n",
    "#   test_set.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnkc58zATKUT",
    "outputId": "1966ecaa-a67b-47ae-d430-3593f68afe82"
   },
   "outputs": [],
   "source": [
    "# print(test_set)\n",
    "\n",
    "# with open('val.txt', 'w') as f:\n",
    "#   for item in test_set:\n",
    "#     f.write(f\"{item['file']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbPiiWIk-x1I"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "5040af4ddd6546f592b859ac99841cb8",
      "d595af9c1f504eb58119980c57e716e8",
      "357167eb78dd4bb596c79659c810c7c0",
      "8baa12445fc9408ba02d1685589bc5d6",
      "f0cb953fbc2f468b8a93d10932791782",
      "6fb52ef254674923958fb63972fead1e",
      "a031fdc39f1f4340ae3475929b5d3b0a",
      "dfd6ecdc399e4736b2605439c899231a",
      "df23d7603f9946a399712de7ded60caa",
      "755400a10b1846319063aa8235e0d9f2",
      "0488a9db2496402292e493473dbad3a6"
     ]
    },
    "id": "ISfgygpHa38i",
    "outputId": "d52dbf87-5ae9-4451-d22b-76b985189126"
   },
   "outputs": [],
   "source": [
    "# input to whisper should be log-mel, this is done automatically by the whisper feature extractor\n",
    "# it also performs padding and truncation\n",
    "\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfbQW1VsdxcS"
   },
   "outputs": [],
   "source": [
    "# load the whisper tokenizer to convert map the indices predicted by model to text\n",
    "\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "811tGIy_fFDv",
    "outputId": "abec18df-37a7-4a90-d793-f4ef4fdd4b98"
   },
   "outputs": [],
   "source": [
    "input_str = my_dataset[\"train\"][0][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFpGhaMYfsQP"
   },
   "outputs": [],
   "source": [
    "# can combine the tokenizer and feature extractor into one object\n",
    "\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFHUNiC6gMpz",
    "outputId": "709ee8e1-e437-4dd4-c02a-1c0cf1f58d37"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl5bbjkqgTxf"
   },
   "outputs": [],
   "source": [
    "# need to sample the audio to match whisper's sampling rate, this does it on the fly when audio is loaded\n",
    "\n",
    "from datasets import Audio\n",
    "\n",
    "my_dataset = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQNbzBPheHd",
    "outputId": "cc114563-5f8a-4404-f0f2-7bd001cff5b9"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oyc3ckpi-1s8"
   },
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "8da089b8edd2455baac9e6cb726c6eab",
      "3f1205de546b48b4a5736ccfca9ba1cf",
      "f1a0d09c321d4eeba28e53e2da035118",
      "cf552f7e463944bf83a2dedca91a304b",
      "4539bf663291432b899da6fc9b4308d8",
      "ca65b9b92bf44c07bff2bb6343bcc98a",
      "f59410cd2209474a9a5c286d04568f13",
      "eb5fbe68723241e9be7eaea82397cf72",
      "db5bb9f6e9ae4c6b8eb13b141e3a0a31",
      "142e2ef98080430381ccee8c1b184578",
      "73f2acacc48743669ad42d61dfc2d184"
     ]
    },
    "id": "mbiL8Ctty2Om",
    "outputId": "c9f9ccde-fd93-44fe-b118-d719693096f2"
   },
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, Gain\n",
    "\n",
    "augment_waveform = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=0.2), # add gausian noise with 20% probability\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.2), # change pitch with 20% probability\n",
    "    Gain(min_gain_db=-6, max_gain_db=6, p=0.1), # change volume level with 10% probability\n",
    "    ])\n",
    "\n",
    "def augment_dataset(batch):\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    augmented_audio = augment_waveform(samples=audio, sample_rate=16000)\n",
    "    batch[\"audio\"][\"array\"] = augmented_audio\n",
    "    return batch\n",
    "\n",
    "my_dataset['train'] = my_dataset['train'].map(augment_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuTiEyvf-9Uj"
   },
   "source": [
    "Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10H8ZZXuhgVq"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0] # its a batch\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "7526ed61ef32407eb9521c727368ce15",
      "4a3b269a77eb4c90b90ac0cb701158fb",
      "9a1b23d669394045bbdd2184482aed05",
      "8d668bedf09e47e59c3d7c673a8e25a1",
      "e4cafc8a37604d04b2f04aa1f1530adf",
      "5a52c0a236dd46f3b701f565db57d76b",
      "ff61449db0a648b1808df15611214fa2",
      "6e6673ca3be84482adf32770016177a2",
      "12aa686fa6ed4778bd4160c3e50bdc67",
      "03576f304e8c4f278da856f97d07c838",
      "3f80999177bf40dd817dafdf2280667c",
      "300b45264a0843d2a96a5c2acee1b8fd",
      "381ae9550286470282d7d92ad49ab4b6",
      "80a16cff0f214cbe8035fad9c126c2ba",
      "e0aa3907676a4d2582a791efb127f240",
      "1387d4c975e94b7ca6cdd379137f6a8d",
      "d586383223114b3ba9bf5ee8d16304ed",
      "c94e32f451b442e582cae8e6f78eb2b9",
      "f579832993c040c0b41a1fb24234a036",
      "fcbc6e17c9d443db9b21058c92986715",
      "a7514f9fe45e4cb384b7474a9080cd6e",
      "224a1355eded42d0aba2ee3af18c152c",
      "09017d7b660141acb792b5554d8bfd82",
      "f07f446323d241d7b9eab209798817fd",
      "fd3fc6dd6e70426f92f444e53c94d5e7",
      "f034c13f2e564707baaa0e5775709d11",
      "36af6790a9be471a8f6b06f7bb23ea83",
      "1e8e7a8814a04dc3bd5b0fbcf4cdf631",
      "9d0b69b6dfbb41f1ba1a6845b8f5d49b",
      "16d4ff04dce14dbd9b7265ec8a59d5ca",
      "3fdf0ef4fc714bbf9c140f8223390544",
      "25d4eb0bdb9e4bb48bf38fd292b38c2d",
      "52dfc21426724d1f96b9e476dd13d0e1"
     ]
    },
    "id": "Hi4uCFqOCUGh",
    "outputId": "7935964b-ea13-4d74-a705-3d7233bcae53"
   },
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.map(prepare_dataset, remove_columns=my_dataset.column_names[\"train\"], num_proc=4) # use num_proc=4 to make it process faster, if gives error remove it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-ONe_m0_P3P"
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "a1b4e6864429440fb384b92ae5f0d441",
      "dc271815b75e4d67ad4a742138084fe8",
      "866013d44d404c979a70a7e411535d60",
      "43a5bf8a2581491c936f0176a406679a",
      "c5b775466d1a4dd5b4a116f62f5e5573",
      "b45ed3b5a89f494c859df211f5662cd6",
      "2f995a6f2f7949129be9a91ae3693ac9",
      "5da719e2f7f84da196e89ce59100c819",
      "4ef3cdfd6d414711a6eafa530549094c",
      "267970aef70d451f86fdd90b2e234acc",
      "25a9aa664a5c4969b4d63f4750890255",
      "0dbdd701d926443687eb94fe4ea2d7f4",
      "2bbc77e7a6a04e4198489dc20a3f5133",
      "36a3a327331144d492c2b9a37f1b3afc",
      "cebf7d72045c47a1a8e13e1d757d20d1",
      "55bfbdf632894a25b0e16c24872ab3b6",
      "dd80705a98ff4a399cbd1140fe54b8da",
      "aa678dc510d04ef9b1805d70f302512d",
      "fed3f164b5824e989d14ae0cdfd0f64c",
      "10c382081d3a483591b94b61474d08a5",
      "297eeb781bf048e89df50908bc98bc03",
      "f3c0bdc63ca142b7b481cad9e67d3c58",
      "1cfe96ee7c904cf1814fbbbd5b7fc2e9",
      "a93348a6da564d139c9f1e382f1082fb",
      "b1b89eb9b2624b27b2cf0d0be0fc0080",
      "a0f4d6edc82a4c618158670e0dce05bc",
      "7c95ee4c093b406983972ed4f4737526",
      "7d4542a4becb4127a5a2cf0e2bc8e4c3",
      "430abeb8ce894cfdb367fb4d909d0869",
      "4976e721763e4b5b96059984dcbd7e2f",
      "81ab9a31fe004b5aa80df797fa9fe039",
      "b84b3784a9154740a0e253ca39a29048",
      "71ada72f090646c18cbf04015f464b57"
     ]
    },
    "id": "jcnMTDyuDLu8",
    "outputId": "984cbdbc-7132-48bf-b338-ae38a8f33af7"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "referenced_widgets": [
      "792b2681972141f9a9ab186a85a354c2",
      "412cd9630b2346fdaa4137884cbb70f1",
      "53b32ca58e6c43029ae165ddd9dcc817",
      "b529b24b46ef463a94ffde3ec252df05",
      "a1d4944e71bc4b718da96174e4d36341",
      "1c4372dca8c34f4fb6a87327adea23fe",
      "dea7614261d44e98b25b2d15c1acbe6f",
      "9e36be9f3dd94b6ea29943b25809c315",
      "f540ed5f30ad4cce9c5823e09be8cb5f",
      "d3421482a1734e7c9df5bd95160aed4d",
      "d72bcd060b634ae482909e521a5a629f",
      "1d77e2ac48ce4c66b470af3f88dbe71f",
      "8f22767291c2464b84980403db09fa6a",
      "5b6c76276f7e413c87af0f8233eb0086",
      "fab432ee0906462fa1ca402a352ad814",
      "70bf5a3094e34d1c9dd9fedd80aeae91",
      "49abd319d8464e55a9a17ae805a3589c",
      "a80e8b09a3734dec8cd6301a0eb08580",
      "5ab71b68557a42fba51827fc49187613",
      "b6566fb67535412f845022238a204d5b",
      "2793ba568a3245dda82c1a1249c34e12",
      "95baa62ddaa8426c985e839d5744e7a8",
      "998e47cb5f844348b55ffeb892dbab4d",
      "116fa433eb9948a2b12e0d0d5c00b2ac",
      "374a68c722f44fbf83375bf0070568ab",
      "d8ae32f0ad90429a9da51a8c89800fff",
      "b8e2b0485a1b486dbc246e20a446a5f5",
      "80fa04996e43420195337f34b4294cf9",
      "4742aec678674f119b8eaecec817896c",
      "9192cc806d124e10b8503eee0f9c9e41",
      "5abcdb70c3804e828473d0a08203cbf8",
      "482bd6a4da8548b99d3bd6c796178529",
      "ad4981e260964078989c3dd1eec86005"
     ]
    },
    "id": "PLwavWMf_tz6",
    "outputId": "8b728716-d18a-4c71-d4c7-3b5337350fc0"
   },
   "outputs": [],
   "source": [
    "# tokens in transcript can't be more than 448\n",
    "\n",
    "max_label_length = model.config.max_length\n",
    "def is_labels_in_length_range(labels):\n",
    "    return len(labels) < max_label_length\n",
    "\n",
    "my_dataset = my_dataset.filter(is_labels_in_length_range, num_proc=4, input_columns=[\"labels\"])\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vn9y46BbD8N6"
   },
   "outputs": [],
   "source": [
    "model.generation_config.language = \"Arabic\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None # don't use the legacy method instead use the config above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PS6l5pxFpwz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass #decorator that provides init function\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\") # pad the input audio and return tensors\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\") # pad the transcript and return tensors\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100) #ne not equal to 1, means get padding tokens from attention mask and replace with -100 so the loss function can ignore them\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rWkWp7nOYi8"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "6b05c4d4e2b44b99bd00c66eeddcdb02",
      "31e3563d2b0644729af47bc36c4bd9bc",
      "b5627266701941cdba303ff67aec0800",
      "b0a0c5e0c12c44f6bb5f8d29bdefe15b",
      "01d31e1e684a499d801b5584f14b1918",
      "44711d4e6cb94d3db0ff8db81813c9ce",
      "9afbb4f557c147f4b1df5ec1639f84aa",
      "a0a4a64e20e24c049835297779874324",
      "588b119327734af2a8bfb043cb1d2c72",
      "5805aa4f59ff462d9e14893495087b98",
      "80acbce89d214f478abea6e8e5386634",
      "90284258b6fd4ae8b3a2ddcef2489dbd",
      "e2dd6594ea7c463d8a3c26c6d1840f79",
      "82af27910de84f6ca5bfef40b55460ad",
      "25a7e4437fce4458bd575bdf43fd7493",
      "d4a72c211a6d47b78eb6cfa31039aff3",
      "fcd5c46de1f8454eaed095696e6b5993",
      "c1d707a9f8c14fd7a3235e7bfffcf814",
      "b7177b8c2933474da38bafc72cfd7323",
      "32e119fbee77470ca95a6336690a6e7e",
      "aaaa47d8d13040f09ecbb382edfae423",
      "0ffbaf1d12fc4965ab9e503d64e49966"
     ]
    },
    "id": "pXUKE-PXObhp",
    "outputId": "e3bd75c6-8943-4667-9dd3-83d59793982a"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "metric2 = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZKsFgspOyt7"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True) # use batch decode to get literal tokens for calculating error\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    with open('refs_and_preds.txt', 'w') as f:\n",
    "      for ref, pred in zip(label_str, pred_str):\n",
    "          f.write(f\"Ref: {ref}\\n\")\n",
    "          f.write(f\"Pred: {pred}\\n\\n\")\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = 100 * metric2.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\":cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYsZ7bRpcSWQ"
   },
   "outputs": [],
   "source": [
    "# model.config.dropout = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuxjJc1fRZZ-",
    "outputId": "827f7067-fadf-404e-cff0-1faaeaa4b091"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-informal-arabic-aug2\",  # change small if diff checkpoint\n",
    "    per_device_train_batch_size=16, # this can be reduced if out of memory\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size, accumulate gradients before updating weights when using big batch size to help w memory\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100, # for lr\n",
    "    max_steps=1000, # train for max steps\n",
    "    gradient_checkpointing=True, # keep subset of activatons in fp n calculate again in bp for memory\n",
    "    fp16=True, # mixed preciison training with 16 bits instead of 32 for faster training n memory\n",
    "    evaluation_strategy=\"steps\", # steps not epoch\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=270, # tokens\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=200,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False, # because lower wer is better\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9Cletk8RaPy",
    "outputId": "77c4c4b0-c250-496c-e417-d0b8cf548cf4"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=my_dataset[\"train\"],\n",
    "    eval_dataset=my_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "5qtVU-ysRl1i",
    "outputId": "85ece454-b8f9-413e-d16a-f49f2929fdf9"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "9Y5fqvCbbH6H",
    "outputId": "f0df177d-6a8b-4077-e839-40a8f150a4fa"
   },
   "outputs": [],
   "source": [
    "# write meta data\n",
    "kwargs = {\n",
    "    \"dataset\": \"Informal Arabic\",\n",
    "    \"language\": [\"ar\"],\n",
    "    \"model_name\": \"Whisper Small Informal Arabic\",\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tags\": [\"automatic-speech-recognition\", \"arabic\"],\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "6c58d3b9c803476d9a1b0e3df7a556b6",
      "176e8ad3c16b410982fa01e8e24ce9cd",
      "67db19df73d3441fa2284b3a2fd08c9a",
      "2b3b5d8ed29b4d92bd76a3d04c9d17b1",
      "067d78ac52e34f8687ef42c0f9d8192b",
      "d09782797594444e9dc3102df5e5ba73",
      "241abcfc480341dba5f3b634468e1489",
      "ca596d003e0e4a618b6d7c9541f1de3d",
      "7a53700240624ecc8f555971c9251b0e",
      "84fdcef3f63442ee8bf5043aa5296873",
      "7699d7eaf91a4d9cb71c8b404fd4869d"
     ]
    },
    "id": "LkTJmv_ZCSpt",
    "outputId": "257756bb-70e6-42cb-d0ec-8ec99146a95d"
   },
   "outputs": [],
   "source": [
    "repo_name = \"whisper-small-informal-arabic-aug2\" # should be same as what was defined when saving model above\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGZdE0zBiGYS"
   },
   "source": [
    "References:\n",
    "\n",
    "-https://huggingface.co/blog/fine-tune-whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXRJ54x9_lhK"
   },
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "270263e9152446608bff2a8b7963c1de",
      "d454c36fc34c4fd2bc289b8168a04dd6",
      "7b404d09f99641d9bd9272ec407c767c",
      "1ae287845d0d49f88fa2c6a1819cb747",
      "0901542e9b9347b1b75bc2029d034d0a",
      "986beb871b6644ddae996dc1417b35aa",
      "4f279693aeda4e6588062800ff91e936",
      "f732fdfbe6834a749efa25f50da58d24",
      "b064ebfac77c4ccea17568b6800a032e",
      "ea1a9690e7ae40e2b7a1092c24f8deb5",
      "2537ebee426042598a69f991a5118f27"
     ]
    },
    "id": "doKyzTaCdPM0",
    "outputId": "934e031d-e189-4755-b0f9-3836cde1852d"
   },
   "outputs": [],
   "source": [
    "# adding tokenizer as it wasn't added before\n",
    "# from transformers import WhisperTokenizer\n",
    "\n",
    "# tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large\", language=\"Arabic\", task=\"transcribe\")\n",
    "# repo_name = \"itskavya/whisper-large-informal-arabic-new\"\n",
    "# tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355,
     "referenced_widgets": [
      "42391924868f4e6180fdc7dd32a2bd19",
      "ccc5a559e8e743d88b4797b4259af521",
      "9c32b9fb546a4a749ffd57d5b1b16318",
      "baab751ee3bb42b7a61801b4cf92fd2d",
      "e425e32d3ac640bdba3a7ac69a123076",
      "3d6fd7b594b245d296484503aee44e74",
      "5e4ff57e715e4272b9d0b2c8cd404b7a",
      "ac3bb62fcbb74ae3a521b8d96feea3d4",
      "5f00cbc3202e4617a3eb3fbff768cd94",
      "f4079daad2984a4d992a14196c513713",
      "88edc9baee0e4ed88a42f1bddf1f8e29",
      "0f400cf90ae147888ce30503fb4a07e7",
      "a91513a5fa424c6d83d58e5b1b6af8d9",
      "078042785bca451db200624b92d8f928",
      "37ae0274aec24a03993a2d24ad478793",
      "4a960e7acd2046b7b6bb885e12d91795",
      "78ccd025e27a47cb8de5e54e011946a8",
      "313e516b99dc45dda58348376ecc356e",
      "c5f9b65979d84e3ab73f622d74a24f94",
      "e8d774bf3c7c4a65acaf942dbed34ebe",
      "fb7a7545d18d4c168e4d9dd8d52e2d30",
      "ca3b0eaefaee4a17b9731b00cfaca7b6",
      "e2b057f53996405bb3c3c2c7ac7b3dca",
      "01e13c8f31224c6a9a1b8e197f85f131",
      "fa3daf88d1aa40c186390bb8b5706167",
      "5648f2ab8b464858b00843668deb95d5",
      "4e0a71a9e7654808a5838df5e821a6a3",
      "f1d53c515fc4479286244d18546b85e2",
      "d3903fd982054f86afc99ce28491aae6",
      "30cf9341914a424eacf30e9fe9d7d204",
      "50119163755f4cd0ae5f171adcdca6e2",
      "433fb78e55e04c40a80a28cd9cb8a3d7",
      "b7ca57fbb5c046f2a70cff283aca71e2",
      "e7ad5a7586ca4b4b82d82bd86cc19a84",
      "95dd1ea1234d40889cd0d52958228d5f",
      "46929dc1b0e044afb7049bf965a7a647",
      "f87fcb38ee074bf0bbb0eb511f6a8816",
      "85564d39b5414dfb848a577165ef8e49",
      "b0161eed80e5495da1f13ef834799bf2",
      "6f43473d83f14619a965101d5bdc8f13",
      "44f74ece688e4861b1ac9550dc0d848a",
      "76031e1c45e64d49af2c3b7bca41aa4b",
      "16140020e4ce43dba296cb20da56377b",
      "b9a0209e7e2847fb93a63014986fd94a",
      "83279ee0e8df4da89dfe05e087b055a6",
      "1d6bc91c442d43449d1b3d3dc3ccb0fa",
      "efcd20d6ecbb44778bf70ce0b5f67271",
      "6addabd39ee5404b90ea5c463af11454",
      "626c1f4a4df54bdba643cd631513f5f8",
      "fe860cee3e7c411f8e1946d0870e7939",
      "d855bd23c4254c67a0eecbe96d342108",
      "b3200c77d2334f179373c21709db2779",
      "84abe020d548466896497ccbc71b7932",
      "c5ddb9a5dd5a4a19b1febae080fa554c",
      "b98abf9c41d949e88a6956355f5edd81",
      "e445e35b66da4056a5c001ad05a6918a",
      "23f0a62e531d426da8deafa8e0431786",
      "dee7fe19cca54b9090880f47a04c5c43",
      "f7934934f90e46a4b7305c725bdd1adf",
      "e2041632744e4a328274d66b25b2004f",
      "0c2747e6f6d64932b9facf63fcb9ccc4",
      "75a76f91c3404a5ea6a7b5a348eb1787",
      "9ce3032d0c37406c9b1914d6e5978a8d",
      "465dc4c2d7904d868a857614ab5fa084",
      "832d9109714a435eb6287814be7e8e8b",
      "9ebd1995b28e488b9291636c94003769",
      "f5f89e03ef7943abb03618e0c4ce47a2",
      "f64db5f4f4bc4b459e18443e5a9b27fd",
      "3caae9532a1d44108fb73de5008f6805",
      "cf9a4fb999c74c3ca09cfac0fecba877",
      "3d2b6295855e4cb5b6d7ccd36801e2c6",
      "54ef5ecbcdcc4274a21fc78034e95736",
      "329f6a2aa5b1442085717dc15cf305a1",
      "d9003ac3b72540008893ebc035f4aa6a",
      "fa351077823749da9e440fa144638bb3",
      "bf1fb422c90b49daaf7b15b245671935",
      "4c50f3a325a54e3a96fbf9cf9faafee5",
      "ec18d1ab20d44c48aed3f52d200d8c7a",
      "cc4311bd41164175bdbdd646b57348c0",
      "2fd4e8381e924905aa295520524811c9",
      "77f1aff0fd7741ceb0e3b55da08c7aaf",
      "4441c7ea21ec49758e4ece7a8ed7bcfb",
      "139910582604400a81448640b693f670",
      "1c927e5532da4a52a28bfd46b43215ab",
      "0a58560569f14fb7bd341e7f3de45c50",
      "a498d655bc9f4ab7a866233ba2f2c4c6",
      "4ba06ae91ceb4b4cbbe9a1430bf862d9",
      "7c9b02fa7c8940aa9ce8665abdece609",
      "8542d9e6a370442981d3687cf8b9ad05",
      "e0bcf36eb8bb49d483fdf1010c33f528",
      "4432a7a775a1428396fe412109098e41",
      "4070fa86aa5048d3b82975898a2d2d5d",
      "356b42552f0846efa87cf3f97fbc2864",
      "bdbed060b52941f8a272cf59b5c4d581",
      "3d0e9392ca4e45a4a24397fcf7e709d9",
      "aa003a68b96d48a88896bbf9343b2954",
      "f454e8b2852b48ea8dea885ce9dd45c9",
      "0b8649699a914497a35604f51e31635f",
      "c5382204b1174fac969db43c4eeaad96",
      "f7a1440d07f940868e891b5efa1a95e0",
      "00d7cb2688cc4c58b9a838fd863d8e00",
      "bf30e2f3d295470ab2b1a4a7176501d1",
      "16c324b02ab04586a3b54f1e0811b0d4",
      "01d4275eae7d4a5db4f7168bc4f0af01",
      "58b909045ab94c40b2f8febf3de36936",
      "c013bf62c4e14344b44d76a35d50c49c",
      "f2ca4d75adf448b1a7de7c79b0cb19b9",
      "a79936c8aa4a476eb5d489c3596ea46a",
      "e0a2d8b6a72a4b64af119b23a928e977",
      "e086ff29c9b1474ba98ab95ab659ce42"
     ]
    },
    "id": "7cA5R9N5iHY6",
    "outputId": "2ad923bf-925b-40d7-c5bc-7e83a1d981cb"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"itskavya/whisper-large-informal-arabic-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmtJHxCai3m8",
    "outputId": "eb677229-b634-4dfb-c9bf-a3cd117cd13d"
   },
   "outputs": [],
   "source": [
    "audio_file = \"/content/drive/My Drive/dataset_new/train/audio/11_chunk_6.wav\"\n",
    "transcript = pipe(audio_file)['text']\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHeC2WeOif4f",
    "outputId": "689feb21-1012-414c-ca5e-b79f6bbdda2f"
   },
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uk8txcdOiVpQ",
    "outputId": "46632962-8050-41ee-e3e8-52109b443130"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "\n",
    "reference = \"شوفي المجال هذا دخلو فيه ناس كثير للأسف الي فاهم والي مو فاهم يبين انا لما اجي اقعد مع ال wedding planner لما يجي يقولك وبعملك وبسويلك وبعملك وبسوي ابد تبغين زي كذا ابدا واسويلك واعملك اذا قال لك ماعندي عقود هذا انحاشي منه معليش ليش ماعندك عقود لازم يكون عقود والعقود فيه بنود وتقرين عقدك زين مازي\"\n",
    "print(\"Reference:\\n\", reference)\n",
    "print(\"Predicted:\\n\", transcript)\n",
    "error = wer(reference, transcript)\n",
    "print(\"WER: \", error*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHFgi0hGpzvv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
