{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIWYNGOIVHGG",
    "outputId": "4f06b63c-5786-4be5-8876-5c2f54d27a7a"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "042c3c6354b8406eba5c5207bc4044e9",
      "50dc692839be4538b91b34a7a50ae741",
      "806ff18f8ca649708a6bc703db706e60",
      "69985e157f0e4dbfb1a8e409f075257b",
      "9a2688c5bfca48faade7ba6735a44fba",
      "627aa45c6e2d4521a1be8eb4a1885de1",
      "fb0caec5486940508b8a15f225cf920c",
      "ac66455baa244929bf485b47dd8b7ecd",
      "3542072309814c49b7461a49f1f15d5d",
      "60a49889d590487e8a5009f9f77ba6b5",
      "86d5278e7e334e079c40b5a2821dc803",
      "03cfaff4f14f46c28118cf9a3e575a79",
      "d100c7428e634613a5e3fbcfa064c55a",
      "cd0b2cf098a2480aafa0fb3c685f2c31",
      "6165f9eff78948ff8097a1f5229abe16",
      "e3e6dabae9ec469a8599dfac78b85d2d",
      "14be847969ff473f91a157d9750011cd",
      "292682bf000242c390b60403da1957d3",
      "2cc44701832047598ff39aabe0ee396f",
      "b236e2b4f804458f82daf9aa806aec00"
     ]
    },
    "id": "upPq9QkpVO5x",
    "outputId": "764bd6e4-a1c6-42af-eb9c-f6878cf8dc4a"
   },
   "outputs": [],
   "source": [
    "# generate a token from your hf account n use it so the model can be saved to the hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASD_AfXT82wV"
   },
   "source": [
    "Run this only in colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvEkDCFusj6d",
    "outputId": "6e0d6f34-dc7c-4c41-8713-277ae915e53a"
   },
   "outputs": [],
   "source": [
    "# download the \"dataset\" folder from onedrive and put this \"dataset\" folder in your google drive once, then use it because downloading from hf takes time on colab only\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')  # Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwhC8fw087Na"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"/content/drive/My Drive/dataset\", split='train') # USE THIS ON COLAB\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63hNqf508-qL"
   },
   "source": [
    "Run this on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "9d39aa5194154750924e9e09a2aeeb74",
      "1b61c99d06974fe59d928afc27758b12",
      "698b075b523349aabf159e26da133ede",
      "0eef7336eadc4f809a0bc8aa29331ecc",
      "8c534d82b314425dafeb905fb0f0e96d",
      "89d7e228d4a74c19971ef6adfb4fb5d4",
      "3b9469eb01cb44cda4b49a591a9495bb",
      "96aeb202ba86420f8e78c6877cda1814",
      "5be706de71234875857585ab4283eb8d",
      "671407294d1b48b5afe789dcf2b236d4",
      "3a80082b0f9d4cbd86c85ddd33e96639",
      "25fa3a20807a4876aa47ed7c435338dd",
      "81186560895c4172901eacd4fe41e78b",
      "7514e0931ac14d02bba785525738e281",
      "52f8c15429a644c3b487f163c7ef97b3",
      "be8cbbc4f64d46f19e06ebbc863d9bc5",
      "c4c71fde4f224ab795a5853ebab08389",
      "12fa7ab55bff46c68aa1bac239f7c31d",
      "e874f526856b451cbaa6a986b06d60e4",
      "636e4b0a074d417b9972b9c4723aeef7",
      "895996095de742e98a2ab8d4a4b7d4a5",
      "f94efc6b60c14030a0f6784735203929",
      "672cbb5286f8483bb516c6783697c84b",
      "5025439b9da94c6c9f82c107b8928c24",
      "f1c65dcb6c4247c98c5be3dbf91f0832",
      "85062c41b386457d8289902ed3918e93",
      "f2d3495e58e04c89ae37f4b80ba0ae3c",
      "497884ee5514489ea99696059f1e19c8",
      "b981eb9a56954d0dbf208786fde8ddd7",
      "9f20506acb6d482e8851b1f3f10b3be4",
      "a557226a488c4c57af71c3083b62e03a",
      "da147608b7b848199a23ac4fa13c0286",
      "595c8dd99aff4df8be733d012f5a48b0"
     ]
    },
    "id": "-0M0dlNDV8uF",
    "outputId": "420b130b-867b-4996-f6d8-a2f10c68f1dd"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "my_dataset = DatasetDict()\n",
    "my_dataset[\"train\"] = load_dataset(\"itskavya/gp\", split='train') # USE THIS ON YOUR MACHINE\n",
    "print(my_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "p_xwpnU6c4IC",
    "outputId": "f28be586-064b-49fe-8f3f-3911293bcee2"
   },
   "outputs": [],
   "source": [
    "# Get column names to identify the second column\n",
    "column_names = my_dataset[\"train\"].column_names\n",
    "second_column = column_names[1]  # Get the second column name\n",
    "second_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCUZDpkJ7m6w",
    "outputId": "3f4260fd-6f98-4ca0-875b-09bfcb2e9943"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Assuming your dataset is already loaded into 'my_dataset'\n",
    "# Here's a way to filter out rows containing '[موسيقى]' in 'transcription'\n",
    "\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if '[موسيقى]' not in dataset['transcription'][i]:\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "# Applying the filter\n",
    "filtered_dataset = filter_dataset(my_dataset['train'])\n",
    "\n",
    "# Print the new dataset information to verify\n",
    "print(filtered_dataset)\n",
    "\n",
    "# If you want to update your original DatasetDict object\n",
    "my_dataset['train'] = filtered_dataset\n",
    "\n",
    "# Now 'my_dataset' will have the filtered dataset without rows containing '[موسيقى]'\n",
    "print(my_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VYPESo2WLBY",
    "outputId": "63d9fbac-64b6-40d8-ed19-bcd4b5d29a9c"
   },
   "outputs": [],
   "source": [
    "# split the dataset for testing\n",
    "split_dataset = my_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WujybCNVZomN",
    "outputId": "1cd8d36b-964b-4bfe-e777-f9f212849cb3"
   },
   "outputs": [],
   "source": [
    "my_dataset['train'] = split_dataset['train']\n",
    "my_dataset['test'] = split_dataset['test']\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISfgygpHa38i",
    "outputId": "38afe3e1-677a-4cfa-8231-5adfb112f0e7"
   },
   "outputs": [],
   "source": [
    "# input to whisper should be log-mel, this is done automatically by the whisper feature extractor\n",
    "# it also performs padding and truncation\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfbQW1VsdxcS"
   },
   "outputs": [],
   "source": [
    "# load the whisper tokenizer to convert map the indices predicted by model to text\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Arabic\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "811tGIy_fFDv",
    "outputId": "4f1c63f6-1195-4bf5-b506-c03ea66fd263"
   },
   "outputs": [],
   "source": [
    "input_str = my_dataset[\"train\"][0][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFpGhaMYfsQP"
   },
   "outputs": [],
   "source": [
    "# can combine the tokenizer and feature extractor into one object\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Arabic\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFHUNiC6gMpz",
    "outputId": "723b2a1e-5af5-4675-bf8e-0f928c92b654"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl5bbjkqgTxf"
   },
   "outputs": [],
   "source": [
    "# need to sample the audio to match whisper's sampling rate, this does it on the fly when audio is loader\n",
    "from datasets import Audio\n",
    "\n",
    "my_dataset = my_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFQNbzBPheHd",
    "outputId": "fd4dd68e-765d-4b76-b663-4e888cbaefcd"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(my_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10H8ZZXuhgVq"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0] # its a batch\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "ac5b0d0f23134ca1a83f065ca521f65f",
      "52911bfbe1a54cc898cd53eb5eba4f3e",
      "4b645cd5706644d3bc74dbac30862f12",
      "9be53a8f83f54b688761b5cbd1c9fb49",
      "f1fac4e3aad64a1e91b76ec7b78c1397",
      "1f1bf7d134fd42039e4069b9b4314520",
      "f91620f3b8fc4e73b800c3fe1572d344",
      "759eb9b44b044eac8952ae12bc2dfdb0",
      "e2cb4fcb0e484c098c2fff35dc3ac7cd",
      "65154e42f2024018a19effde7a9e0f68",
      "2017a7a1b9ed411aa7b9804999f06f56",
      "f296bac79eab449dada5abee9daae2bc",
      "a1102ee3f23e4c63b1bf2bdc1cc20cdd",
      "5bd956fa310f4699ac68d33657ae7dc6",
      "6e998408882c4757b35f8722b20b298e",
      "c26b6686e523479db57ba39c9c6be993",
      "a16253461d30420d97b1fe879e2771c4",
      "95b42393b7044f55ac200181c93a6364",
      "1946c2f0248b4c948a849a097c0dc342",
      "41210561f0184925a29e394e6930553d",
      "534e5de7ada84a50acc0bb60f2159749",
      "32b5753ae6db49fb87f669c7d767b499"
     ]
    },
    "id": "Hi4uCFqOCUGh",
    "outputId": "64aa4adc-5638-4f0e-c7aa-ce7b781dbc7e"
   },
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.map(prepare_dataset, remove_columns=my_dataset.column_names[\"train\"], num_proc=4) # use num_proc=4 to make it process faster, if gives error remove it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "7e60462d95694ea8aafa0809ad5ab347",
      "6c67622f76dc47e58cf3239215829c9a",
      "e1f75c30fb14464b8a09fb79c5b84070",
      "17bc4b9516064454a720088d144809ac",
      "551a3090c7d641b895d65d5c868ce440",
      "07cfeac4431e416eb6e5ab0e5ab3698c",
      "79ea6d1b0e72427a99ce514300886f13",
      "fca0ac18cc2744c7a965c9ff5edaa54d",
      "8f2a7cc1af404ed1930933f978e47be7",
      "87a3d194d1cb4457afe32f9bd92566f4",
      "2f12b4dffb5849b289cdfeb194b8117b",
      "d9b7c1d7dab7400c8755b65a8bba0337",
      "ddc07e59730f4725a22590a26f0219d8",
      "b2b704165b9a40a898a35866f98d4e91",
      "575014afc8ed4f4da9ae6d59c42e0ccd",
      "52f9143c8bc54059a7a35fbf4c4bd01c",
      "9c53aa28814e436ea258ab08522e740c",
      "d530110d07f841278cba4c9d3e551fda",
      "6b45879cf89d4dc1a9421a5b67fdd35d",
      "10dcb72570f745f18ea4084844cb6fe0",
      "fa961215665b4b81966765050c7882e8",
      "5b9998ade9774c2b9795e80444bfe182",
      "9792623f13d84c19bdd7de89aaf4ec7f",
      "129170ea62fe40ce8ee34ded60af10d3",
      "9451489b78fa4b0c9505ed0ff00420e3",
      "dd43409b23b341d585938e3b8d1c2578",
      "73cc65f30fb84474b52e2b1edb787c43",
      "689038fd31d844b6a22c78be2cfcb35c",
      "1005f318ea2c4bbc8b7d50ef8db4f69e",
      "1b1636165db34cdf94d200dc31bc2383",
      "25e70b9186bc4ba0a36c02a594d24f38",
      "857ae18e7e1a4fb48c109e4502c85f4c",
      "54800ed15a4046a4920c1a76ba172aaf"
     ]
    },
    "id": "jcnMTDyuDLu8",
    "outputId": "d4799c71-725b-4269-a388-ea259b60b4fc"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vn9y46BbD8N6"
   },
   "outputs": [],
   "source": [
    "model.generation_config.language = \"Arabic\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None # don't use the legacy method instead use the config above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PS6l5pxFpwz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass #decorator that provides init function\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\") # pad the input audio and return tensors\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\") # pad the transcript and return tensors\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100) #ne not equal to 1, means get padding tokens from attention mask and replace with -100 so the loss function can ignore them\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rWkWp7nOYi8"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "adcec11922d049efaa54344563fe8513",
      "0d4d872bca6d464ebd0e3e16fe0167d4",
      "f8e57f9292294a278ac0b036438a18bd",
      "b7e4e433f6524fa4b197f4496e5cc862",
      "1978ad2acf9b4307984f00d87817e551",
      "05bb73dd664c40f6a99b39f0780752cf",
      "7ccc5ba227984a398a35cb5958dea9e3",
      "fb146ce5621646febcbf101e53ffed15",
      "f57fb733072b41c3b9ee9d325abd10fb",
      "7cc1c04d860c428cad45b3ad1a0449b9",
      "6e0c56297999477cb71aaaa4daafdf7b"
     ]
    },
    "id": "pXUKE-PXObhp",
    "outputId": "5dd35cf1-1def-4f43-8253-4afd99d7b505"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZKsFgspOyt7"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True) # use batch decode to get literal tokens for calculating error\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuxjJc1fRZZ-",
    "outputId": "d31d6e6d-b90b-41e9-d69f-76d99775ce31"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-informal-arabic\",  # change small if diff checkpoint\n",
    "    per_device_train_batch_size=16, # this can be reduced if out of memory\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size, accumulate gradients beofre updating wights when using big batch size to help w memory\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500, # for lr\n",
    "    max_steps=5000, # train for max 5000 steps\n",
    "    gradient_checkpointing=True, # keep subset of activatons in fp n calculate again in bp for memory\n",
    "    fp16=True, # mixed preciison training with 16 bits instead of 32 for faster training n memory\n",
    "    evaluation_strategy=\"steps\", # steps not epoch\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225, # tokens\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False, # because lower wer is better\n",
    "    push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9Cletk8RaPy",
    "outputId": "9ddd6314-b08a-44f2-89cb-9cbdbd930f07"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=my_dataset[\"train\"],\n",
    "    eval_dataset=my_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qtVU-ysRl1i"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y5fqvCbbH6H"
   },
   "outputs": [],
   "source": [
    "# write meta data\n",
    "kwargs = {\n",
    "    \"dataset_tags\": \"itskavya/gp\",\n",
    "    \"dataset\": \"Informal Arabic\",\n",
    "    \"language\": \"Arabic\",\n",
    "    \"model_name\": \"Whisper Small Informal Arabic\",\n",
    "    \"finetuned_from\": \"openai/whisper-small\", # should be changed if we use diff checkpoint\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaNo6bGvbJz3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGZdE0zBiGYS"
   },
   "source": [
    "References:\n",
    "\n",
    "-https://huggingface.co/blog/fine-tune-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cA5R9N5iHY6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
