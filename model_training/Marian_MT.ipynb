{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LIRkEfHYsGw",
    "outputId": "40ed610c-276a-4cf8-a981-2f0d59d32cd2"
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GmHd6aaZygy",
    "outputId": "fdd7ddaf-43f8-46f1-cd3c-b12d592df2a4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')  # Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KLBhgR5YbRZe",
    "outputId": "0661dd4a-8a6c-4138-fcc4-942d40a54714"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_excel(\"/content/drive/My Drive/combined.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "irn9g48kbjUo",
    "outputId": "ce3d58bf-8660-4149-ce4c-9f1d1f9f92d9"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "danoSCjKaZAz",
    "outputId": "ed792405-783d-437a-b15f-950c4575362b"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "my_dataset = Dataset.from_pandas(df)\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2zWpk9Rh3wS",
    "outputId": "d2607b9c-392f-484f-8ea1-8d993d9ce958"
   },
   "outputs": [],
   "source": [
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "056ddb6cbc1041afa3d45e22b95346bd",
      "f468e61295a34c5b979e33ff4fe83781",
      "24cd1beadd4344c680a4cb50a1978fc1",
      "551db343d9a14dbaaecb267ec5eda4f1",
      "e1ccbb6b994e4e8ba81fc45cb11d672c",
      "748e2ed66ad340aa876bfb169091f1b5",
      "24b45cc7816f4cb0a680f0e25dea67f3",
      "111ed3007cee4cb29987a340b323f66d",
      "b021ba3869214ac3b315c0f58cb04a1a",
      "a18c05bc996642fb889f0f3600ad8c4d",
      "0420eb42ff444b40bc2f92264376e036"
     ]
    },
    "id": "un1FDvWxftqN",
    "outputId": "760a3554-e6d3-41b7-8d59-f6b45c58eab3"
   },
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "import re\n",
    "\n",
    "def clean_arabic(example):\n",
    "  # example['Text (Arabic)'] = re.sub(r'[.?،,!:\\\"\\'؟]', '', example['Text (Arabic)'])\n",
    "  example['Text (Arabic)'] = re.sub(r'[,]', '،', example['Text (Arabic)'])\n",
    "  example['Text (Arabic)'] = araby.strip_diacritics(example['Text (Arabic)'])\n",
    "  return example\n",
    "\n",
    "my_dataset = my_dataset.map(clean_arabic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ij2__EJ4ehhs",
    "outputId": "0cd88723-cbad-4826-9cb0-79d393c78ae4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['Text (Arabic)'])):\n",
    "        if bool(re.search(r'[^\\u0621-\\u064A\\s]', dataset['Text (Arabic)'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset)\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ko3tixRfX4O"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['Text (Arabic)'])\n",
    "  # print(filtered_dataset2[i]['Text (English)'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7XhJBgIxqMo",
    "outputId": "c7fcee7d-f2c3-453e-9361-bdc1d7dd4d47"
   },
   "outputs": [],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7e56e90fa0164f078e6e4f9abd0b76a7",
      "14d83bbf4a684c9899b9dab6144a31d7",
      "2a5a6ee75bca47e68017dba5be9ebb8d",
      "ef2aec590e864ea08cf22e1423c82def",
      "6da8c79389954ed085dc56b5f0273581",
      "3eed60c2889841f0bb9ce10dc6a22a8a",
      "bb893f2fde40494f98425d62e8aa4f95",
      "e45b738d8771471bb5c05430642ba9cd",
      "31bbacc3712b48599a074b4ed505970d",
      "8091863bd56f47998a940c70ddbdf6f1",
      "79fa7aa832fc43ce85ca5c8a8d247348"
     ]
    },
    "id": "qzB5_GbHnZjB",
    "outputId": "3cec4b12-3525-42e3-c764-286f913a2f7f"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def clean_english(example):\n",
    "  example['Text (English)'] = contractions.fix(example['Text (English)']) # this expands words like I'm to I am\n",
    "  # example['Text (English)'] = re.sub(r'[:.?,\\'!;()‘’“”\"*…]', '', example['Text (English)'])\n",
    "  # example['Text (English)'] = re.sub(r'[-—]', ' ', example['Text (English)'])\n",
    "  example['Text (English)'] = re.sub(r'[\\u0621-\\u064A]', '', example['Text (English)'])\n",
    "  example['Text (English)'] = re.sub(r'[()*…...]', '', example['Text (English)'])\n",
    "  example['Text (English)'] = re.sub(r'[%]', ' percent', example['Text (English)'])\n",
    "  example['Text (English)'] = example['Text (English)'].strip()\n",
    "  return example\n",
    "\n",
    "my_dataset = my_dataset.map(clean_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MQuxO7Z7n_uI",
    "outputId": "5ff2314c-5e44-4cbb-d8c2-364d17e3c2a0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['Text (English)'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\s]', dataset['Text (English)'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset(my_dataset)\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-FrPDxznu3X"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  # print(filtered_dataset2[i]['Text (Arabic)'])\n",
    "  print(filtered_dataset2[i]['Text (English)'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI3NPuTRdJaw"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint=\"Helsinki-NLP/opus-mt-ar-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXuyx3i62_hw",
    "outputId": "e315a5a3-fda7-4a52-8f00-832fe5eb980e"
   },
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0n8zfM9skyve",
    "outputId": "96cc745c-b6c1-4a3c-86b5-4ebde816d56f"
   },
   "outputs": [],
   "source": [
    "print(my_dataset[1000]['Text (Arabic)']+\"\\n\")\n",
    "print(my_dataset[1000]['Text (English)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpPZZYWIjVco",
    "outputId": "1de9a363-a2d3-4604-fb2b-8dedb1aa2757"
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize(my_dataset[1000]['Text (Arabic)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aI-N0eJmlerl",
    "outputId": "0a792525-bdfd-4dd9-e7a4-22fba82a77f3"
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize(my_dataset[1000]['Text (English)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYu47_Bga2-Y",
    "outputId": "8991761f-e682-4a3a-82c3-f2a9db006497"
   },
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.train_test_split(test_size=0.3)\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zmtb0bAwMA-J",
    "outputId": "a104f0cb-75b3-4a0f-cb54-d1732bc32c6e"
   },
   "outputs": [],
   "source": [
    "my_dataset_test = my_dataset['test'].train_test_split(test_size=0.5)\n",
    "print(my_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Nr97uZJMTGS",
    "outputId": "91146899-ef16-453b-c942-9e94d3cc2dd6"
   },
   "outputs": [],
   "source": [
    "my_dataset['validation'] = my_dataset_test['train']\n",
    "my_dataset['test'] = my_dataset_test['test']\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XwxmJRsoyMY",
    "outputId": "d1819586-50ac-4561-bc12-bcb6db0e3ca5"
   },
   "outputs": [],
   "source": [
    "# Tokenize the sentences and calculate their lengths to find max length\n",
    "tokenized_lengths = [len(tokenizer.encode(sentence)) for sentence in my_dataset['train']['Text (Arabic)']] # for eng do 'Text (English)'\n",
    "\n",
    "print(\"Tokenized Lengths of Sentences:\", tokenized_lengths)\n",
    "\n",
    "import numpy as np\n",
    "print(\"Mean Length:\", np.mean(tokenized_lengths))\n",
    "print(\"Max Length:\", np.max(tokenized_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIH7lCnk3Qua"
   },
   "outputs": [],
   "source": [
    "max_input_length = 195\n",
    "max_target_length = 390\n",
    "source_lang = \"ar\"\n",
    "target_lang = \"en\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # inputs = [ex for ex in examples[\"Text (Arabic)\"]]\n",
    "    # targets = [ex for ex in examples[\"Text (English)\"]]\n",
    "    model_inputs = tokenizer(examples[\"Text (Arabic)\"], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"Text (English)\"], max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "61b6a5a209ff479592224448d7fb6e07",
      "70dfd7b7b1c147dba9e64866f9d8884c",
      "3e8640dd43d549e49da9e058f54d7d9f",
      "f54eb67d3173475aa41c8ec3e79769ff",
      "4769f5b37a5842509ed304e87e61b049",
      "5e7caf089fc44724a1c1f54346930e5c",
      "7b791b11ece34cc59553900d4c125c26",
      "ae6cf4e9817c407886fa51b72d4a7df2",
      "66e67a81b7d64170b3ca38c8c6dfc65a",
      "d01f94a7d8844458a29fcd2b21a37cf3",
      "bded9c8e2bf44527a32df3afe8c7c49e",
      "541f90204f5043dcbe483ae06f0c5fd3",
      "753cf1aeb4c44ab5b0f3f8960e9f7162",
      "df3c9c028ba144d1b15a91436ecbf1f9",
      "f0f5f260245c434d9ef041bb07666e11",
      "e914515e9a5b4324a4039f77620086c3",
      "097e1080c46a4ddc8478d6a14a8c0ef6",
      "cb37dc6b4ca24e1dad2c61caf3cccf93",
      "2c0998674f5d4dfda7125df6557ddb9b",
      "e5942bf0113e4c9f9474445687e8e9f8",
      "3c8c69d241e34b678a1e73d6cb2dc315",
      "0d288fe9276e4bda80413632d8a689da",
      "a48bb6125b404c7a8e27508fe89cdcc6",
      "5b1ee3947ca54fd3b2ea7d84c2e5f883",
      "687827606e954dd093319e38c5547f30",
      "15d61b8c0e4d418fbfe5bbed68499c51",
      "467e23e4677d4a6cbae4c5d449a71c62",
      "19a24d1dc7cd4f9680ff923bf1ca07a3",
      "e6181946eaa1405485cd5800e5893fc1",
      "f3556ed53a534676b8418505005f7d84",
      "e2c6a922c2654599adc44378e3a99eea",
      "2a79d93a52f34ac2a0bbfdbec4f88557",
      "09ab661c6ba945dfb38e31ee3fbec80d"
     ]
    },
    "id": "KOT9f3rm4Gmg",
    "outputId": "9a5e774a-cc39-4e9d-b0b8-026b45eff15b"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = my_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOGiKe8L4Mca"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP1H6F7o43v2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT79BlGc7tiF",
    "outputId": "6954d34d-e4d7-409e-d591-a40f87eeb53f"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKcfGpB-7tBd",
    "outputId": "7fc1a98c-cb84-4d16-ec11-f793a03372ec"
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "bleu = load(\"bleu\")\n",
    "meteor = load('meteor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyzEPubiqNq9",
    "outputId": "5da22d43-b26f-4b9b-fe85-f7eb83bda95f"
   },
   "outputs": [],
   "source": [
    "fake_preds = [\"Is there elevator?\", \"I've seen him before.\"]\n",
    "fake_labels = [[\"Is there an elevator?\"], [\"I've seen him before.\"]] # list of list when multiple references so can remove it\n",
    "\n",
    "print(bleu.compute(predictions=fake_preds, references=fake_labels))\n",
    "print(meteor.compute(predictions=fake_preds, references=fake_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7f-lC4v5BPd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "  preds = [pred.strip() for pred in preds]\n",
    "  labels = [label.strip() for label in labels]\n",
    "  return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "  if isinstance(preds, tuple):\n",
    "      preds = preds[0]\n",
    "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  # Replace -100 in the labels as we can't decode them.\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  # Some simple post-processing\n",
    "  decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "  result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "  result_meteor = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "  result = {\"bleu\": result[\"bleu\"]}\n",
    "  result['meteor'] = result_meteor['meteor']\n",
    "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "  result = {k: round(v, 4) for k, v in result.items()}\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "42dc188a07644e37b7af6f99326c3f0f",
      "a617d608452f4f50a78e2483367c25f2",
      "e592571bca0d452cafc6093641f3316e",
      "132f62c2939e4e94a128c479470b3e88",
      "733fc723ecf44367b994d8553ea58923",
      "fb680df740514690a931e12702506179",
      "ae66818274d24a75aaf4c5c881360add",
      "8d7b2d99002f4f0ba7ae5fa906541ef8",
      "8ac0c32e18cf48b2a6c65ecf4c9b0778",
      "ab26944c853a48f296da164048eec7be",
      "79fe8f9a45ce4a1aa8b5c00767225b5d",
      "69798574c5b949cb90c97b4817cf40b2",
      "f8002d2ee2ec40fcb88b38d7d8b359b2",
      "1949d7c94af24b80b0a1a3cf51ddcd2f",
      "80747431e7e44b549e1d174f2a568aa8",
      "87d856baa4be40c689c934f4c0596910",
      "0ad549ba7f6e4b628a7987dc46b35679",
      "a9d7a4340d604364a50fcdea2ed0967c",
      "7cbf7638700945e295303d6edaba6fe1",
      "9f27bcad31634a7c91bfc525d0b5ac13"
     ]
    },
    "id": "OKBrb28e8JbR",
    "outputId": "bbe82958-b87b-4dff-f0c4-5c3cd8108c92"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6P61Mj-4U75",
    "outputId": "d286a2e9-c986-4514-fafd-a98bfa5c025d"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# try diff parameters\n",
    "batch_size = 4\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}-6\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.001,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    "    warmup_steps=20,\n",
    "    lr_scheduler_type=\"linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdBjdpom5DX1",
    "outputId": "93376d70-ecb1-490b-9f96-a4e3e0e0cc11"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIv0LbKc7hzQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"WANDB_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "2vDVE1Bd6zLA",
    "outputId": "ad0a083b-0c5e-43fb-9a5e-8d90ff0065fd"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import time\n",
    "\n",
    "# run this before every run so it doesn't overwrite the previous run\n",
    "wandb.init(project=\"huggingface\", name=f\"run_{int(time.time())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "YA4x8ve_5Gm_",
    "outputId": "410f0384-4c1c-4d80-f4dc-81f806d73c7b"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "5Sf-bT2CNFBP",
    "outputId": "04400ddb-f90a-4e87-a861-2aaa6a2a4d33"
   },
   "outputs": [],
   "source": [
    "# close it after run else it overwrites then try next run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "95a9d35289324bb8af306afb4f3848e7",
      "a1e41f6ee21b415c9de0650b97c24c0f",
      "ac3278f69f704099b34b6451352dcb71",
      "5be2e669ef4f462885296eb4980770dc",
      "e0c914cb357e49c4b2c3f8af5e017ee2",
      "94d823abe6ee45e9b7f4eb7bf205da74",
      "ea4032ce7aa64c958da3d2f58c0efb82",
      "bc50fb76accd482f9cea07ddb38aa985",
      "37e9d0011b634b21af0b884b798f5c69",
      "72f8ef2b25294a86a20e181b26de5158",
      "5bf6c5c0b28d4088aa5d490c3972f649"
     ]
    },
    "id": "eqAfW2Evwgym",
    "outputId": "66d70fdb-a0a1-49b5-9839-6a9b5abbd489"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARrUmTlwwDbL",
    "outputId": "071edaf3-0220-4373-8bc2-ab809f4b7753"
   },
   "outputs": [],
   "source": [
    "my_dataset['test'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291,
     "referenced_widgets": [
      "a0ceb4d80db04d8aab10e1bb9771168d",
      "84d1bd414c254c339d9109dbddd7d212",
      "831c883240fd425cbab1bd676f7e3c51",
      "633f9ed7c4d44163b57b590f79c4399c",
      "0f189e8061864a37841c4965537d100d",
      "d751b90367674a58beae7fcbd3ed445e",
      "600635f0ec26468886d528e7626345b1",
      "dcd0b6d8c8e34dbc9be96543dd77107b",
      "591224c2096540889fd0abf931e42dc0",
      "ee4f5da6d0174df4b86570a950d3a2ec",
      "43b2435f039d4671b9b338f4f82605ca",
      "a60d1b61929f4a8f98b7c8386a51a66f",
      "e0bb5bdea1fd438f9f26476f2ef8cbda",
      "3c6a3fa21d954740a3ccce7f13304a30",
      "e1a02506b6b24348b567d2dca6e0cc97",
      "fbc3fc59ddf6451c8e5e745adb7839af",
      "bfde1f2144784cb2820619a64347e597",
      "f7f2fb5cef0c4024864082582f7db7ce",
      "40122b9edadb4a0fb5e5356389264a93",
      "9e8b7875c78e447ca93a793323941573",
      "f51f3058563c46b1a7967d7afcaf9e4d",
      "2bfd111294624a7aa67916b139e54631",
      "9393957ec930499cb8e2b24edf0b7834",
      "97edb822526249d1b256383381e5ee70",
      "9f96079edeb04b27a192cc2d50271c52",
      "cf3eed59c099462f9eb37d638159fc86",
      "6ee35f5a8c26460b9855b2f66d14c919",
      "0a0e259ba6bf45b4ac972a131b46f283",
      "c3892d92ca174b32a2580d8737186538",
      "fb26005fb5c04590a6720cd9b0da14cd",
      "02154ef8d96d4b0fbda5b803fdbd9206",
      "658d1623ea9146408878468556ebeeb6",
      "030d37143baa47cea0ac0b5e0cbb7d4e",
      "cb5d0566bc364ae9849ba70926aaa96c",
      "b90a1d38fb394d149994756abf0e98d0",
      "756e8a480f5d466a98733649d717fce9",
      "25e30482c93e41e8843a4c80f8bb7953",
      "53759cf806b5458aab0770d572c583e9",
      "83133411380d4e57896238f907c837ad",
      "1b0c33e603fc4711a051a00e1c0ee4fc",
      "f63f6bc28c664fd495a07680660e7137",
      "a2aa3e2dc21a476cbe5ff5498c106fbc",
      "d4ba36b5265844ceb100fd1caf00ff0a",
      "b706359c4899477aa50f34a395c86dc2",
      "88e4fcd595854ae18fc069cf8f331ebd",
      "baac25a271ca470eae5c17c67a3bcbec",
      "2d21afbfd5ce4bbf9b13e8241c7f723c",
      "c49a895a82b74361a6c1c1020a08af8b",
      "47ac7d9e5d2746be92068f2440a0971e",
      "b2a0aeb3442b4563a117f7b6f63e3515",
      "4322a9cb2e4543afb1442e1872715d23",
      "a8fa55bbbf2e492ba7fe78f93291bf76",
      "f0180946672e4600850d862468fb4578",
      "cb7cd6a1214745c88093f999c0bb0836",
      "cdb02daa06794001ab87c00181009efa",
      "b59069cf93ac48b981a3542d5c55c0a4",
      "71fd798216a54889b067e4e5bffae31c",
      "564951c34b1047ef99bec23fedd22b13",
      "e29e76e6f82541ebb7b9db4270f0d36a",
      "c7d2ebc8bbae4d13a2239e0770b56115",
      "c15c7609a5fc4267ad98295a7c90ed50",
      "8d94ad4a2d494c3ba348cb50b1e01fa1",
      "94a159024127457aadbeb8a5fd355263",
      "b2e6346adf824697a6386c47475c97b0",
      "e5fc60e74aab45f4bee3004e3d62b735",
      "2205a031e5c943d0a053bc0c3c327fdb",
      "0b9d207f4efd4daf9c8c7db9a8e19d2c",
      "e10db94725784b458fa2fb99211c1989",
      "6002b80952db474c992a80178df7af27",
      "a32c56143bcf43039cb9e4cd2845df9e",
      "2a77a089d2fa42da87b45ed863b75f34",
      "ded7bc79e4204a1899f5bf9c4f890634",
      "eb3c67b22fba4ab4b98eaabceaabd6fd",
      "45a1ec7416c34f7bbf721ff6b35469b4",
      "ec662ad3d2ea44a8bad9aa671ba8a1ff",
      "684d8e0d110a4708986a262821223676",
      "6a7d82b0d7914162a2175df9f9b97a39",
      "2cef365a78ef4479a4af53272db5bc23",
      "02a4ee5c6dcf48b387844bdf6dd15f34",
      "4ca4107d285149b2a4a9acbea533cf16",
      "1b265bfd1fe14c8aaaf45c7af6868769",
      "8f02a78a11b44ea08280f2f4dfad197e",
      "3e38451a0ae749989c03c806dc45590e",
      "c72fbd7aa70d4dad95497eccdf34a636",
      "18b6c34ce0134f29beb778e5f18fbf0b",
      "469a9a2227b7493aa8d907db66602047",
      "709d8962eb914ee69e72410da4d73912",
      "4aad599e69af4a48bac415d501348be8"
     ]
    },
    "id": "zt1tysnY8p6m",
    "outputId": "1ec3228c-db0c-4319-b543-d4d119f7d321"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# check some translations with trained model\n",
    "src_text = my_dataset['test'][2]['Text (Arabic)']\n",
    "\n",
    "model_checkpoint = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True)) # can try more parameters\n",
    "[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6usbHFqEESdV"
   },
   "source": [
    "Referneces:\n",
    "\n",
    "-https://medium.com/@tskumar1320/how-to-fine-tune-pre-trained-language-translation-model-3e8a6aace9f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWsoq-D3xDNX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
