{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMdMfk3rnGrx",
    "outputId": "15de6f8d-2913-4edf-a935-04c7ef7d4bab"
   },
   "outputs": [],
   "source": [
    "pip install transformers datasets torchaudio jiwer librosa evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "08a6b7904b77476cbdbc8c074e3bbaf3",
      "81d054ce0c894ee794467f0a8a250c6e",
      "2325d1a54fb046f7a53470b6bd94f9ee",
      "f0165718db2c496faae14b762067f13c",
      "6fb7641bc7324e608b5ad6aaa03f08e5",
      "1a61a63d1b244eb0a9e940fad5b72193",
      "32906adffb674934b5db7b8e18658403",
      "496f1b52e18d4b1fa4bc76644497207e",
      "e33c1b211a9d4e96835ea9315b2fdda1",
      "65bf16ec39a148cba5c5b08dc6c980c7",
      "d94c76c4599449de8938fce087478dee",
      "77d87311dc67445d829d12482b4ed919",
      "3f6d66eadddb4f60bd545407c6200d59",
      "11b00e7241124377bcf2fb7056245d40",
      "1fe71cb653984a9b97c0a39167f2b909",
      "9620f374e6b64231af1cf93f1554ecad",
      "4be40d36f7b9446aa678619f1fcfcd6d",
      "5ec62842f90a41698302f11ceab33ce4",
      "b67a91cd55ab4e14a358316959834d48",
      "5f1ad2cac2c14280ba06511cb84cb967"
     ]
    },
    "id": "Xx7ibogts1wz",
    "outputId": "40e75373-6f0a-4b9f-dcf7-e378fc6af351"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhyjQVNInIYQ",
    "outputId": "d4ba3563-9e54-4852-b2ca-70db925c9f4a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "f425c5bf753f4772a95f456f7f2261ea",
      "16de6cb9eca34c5c990ff3a667297f16",
      "608bf220b3264f0bb8031c941a56ebf3",
      "45dac3c6f26a47d68f78061da75d4655",
      "497b7c8aa3524f3aa89ad7d73ce1c0de",
      "dd13e9967ab24015a863c9872cfdb0c0",
      "a2369c92fde84179aa7528d521d2554c",
      "e8cf0be10de0463db735e039b7d95d52",
      "c89019b7e7024a5ba9e0fd4b2d5f282a",
      "0e49f5d5d06a45f5b9c06d513c274b08",
      "849a3779f337480fb2e83e53b1e9d939",
      "f5d3463e4dd84ce282ac773b1906fcf3",
      "52e70bf4ff7b4a4594e0f7f7f4810e2f",
      "d73a5d20a2274d9abc54eb54d83aa7da",
      "5d1105c5f72f4885aabee0550b389d4c",
      "59b4cba37df043b6a6e3a447d04b3a20",
      "39d112bf04834b9aa08805310edc9ca7",
      "29b2618a6d584d10abe462388ec35ecb",
      "b69a51f2b6b446819b4e6ee41e8e5b8f",
      "150344df39d646a1af3fe6c600f59db2",
      "1c1b04851487486bb9e2f3ea395dc4e6",
      "f70e71e8eef84b06a349bf851ac2e111",
      "09de9c46399f4dd193b8eb534be8e2f3",
      "47ff37b2c3ce4930930686c16f3ecd8c",
      "c432155654024ca7bf374413595402b6",
      "9b56ae4f5ae24db18965383177ef6185",
      "da3cfc18d9d84dee9e897a8f51fe605a",
      "af2f8f360ae54584b9c4f75f6877ea93",
      "377133064a5340dc97c03b87ff0cf8d6",
      "6f963c26a401489985cdf9d32be45092",
      "fe87ed25ff4b45b68455697998ecbe38",
      "6c81b6aa65ed40c28d771a5cc05bdde9",
      "2feb19df609141b18c5baf12c640b2de"
     ]
    },
    "id": "oBVidZ03lzfT",
    "outputId": "dc699adf-eaa9-420b-8e79-6a05b9759be0"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset[\"train\"] = load_dataset(\"/content/drive/My Drive/dataset_new\", split='train')  # Works in Colab\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Tsd429O-9T5W",
    "outputId": "8d4dd8a3-4303-455d-eed3-42a2ed437885"
   },
   "outputs": [],
   "source": [
    "# Get column names to identify the second column\n",
    "column_names = dataset[\"train\"].column_names\n",
    "second_column = column_names[1]  # Get the second column name\n",
    "second_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "261b6074715542ee96c6e6bdc1e5eeb4",
      "2dcefd45c1d14794bfafcfdf30ec670e",
      "bdf9d9ce6cc34f748bc49729b9ae415a",
      "a730147a47544bc794e163296d161d10",
      "73be6a82698f4a0a8841a1309b156309",
      "ea4230f5a57b4745846b98c2188268e5",
      "cafb0678961741abb3007b229dc55d0b",
      "ec569c8cd42b49788363571dd7a2b70c",
      "65d7fe21540c45d2808cf72b5d4ce6c8",
      "526392ac9a4749b28b52d226905ef267",
      "3db7868ba34547f2b34ac15378d1377c"
     ]
    },
    "id": "TBPFyqsRl8JE",
    "outputId": "646696ea-bd1d-40a1-ccb5-c9c8dda7ac01"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove only punctuation & numbers, but keep Arabic dialect words\n",
    "chars_to_remove_regex =  '[\\,\\?\\.\\!\\;\\:\\؟\\\"\\“\\%\\‘\\”\\�\\.\\،\\-\\']'\n",
    "\n",
    "def clean_text(batch):\n",
    "    batch[\"transcription\"] = re.sub(chars_to_remove_regex, '', batch[\"transcription\"]).lower().strip() # lower so vocab doesn't need capital chars also\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1llKNQB4fVq",
    "outputId": "36249e34-11b1-4008-8220-4ddc07e874c8"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have anything other than letters\n",
    "def filter_dataset_2(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[^A-Za-z\\u0621-\\u064A\\s]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset2 = filter_dataset_2(dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvrY0L8LHuZl"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdOL2Qxq8vw9",
    "outputId": "2de046ff-3c78-4d63-8624-0a781b03f6f0"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter rows that have both eng and arabic\n",
    "def filter_dataset_3(dataset):\n",
    "    filtered_rows = []\n",
    "    for i in range(len(dataset['transcription'])):\n",
    "        if bool(re.search(r'[A-Za-z]', dataset['transcription'][i]) and re.search(r'[\\u0600-\\u06FF]', dataset['transcription'][i])):\n",
    "            filtered_rows.append(i)\n",
    "\n",
    "    return dataset.select(filtered_rows)\n",
    "\n",
    "filtered_dataset3 = filter_dataset_3(dataset['train'])\n",
    "\n",
    "print(filtered_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcPaohSz9H-A",
    "outputId": "55cbe3bf-1362-44db-8134-938e490b72a3"
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_dataset3)):\n",
    "  print(filtered_dataset3[i]['audio']['path'])\n",
    "  print(filtered_dataset3[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iRlv3PP99qz",
    "outputId": "1260a9d9-5e78-43af-fdac-7057f602c15c"
   },
   "outputs": [],
   "source": [
    "!pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "8d75764880a2433bb6547199d059951a",
      "c97c2007a3f94f94b03995d2166d2e1d",
      "12a239140f7a481395798dba856fd2fd",
      "a3098b192b014d078c99e9ba35df2cdb",
      "ff617491dc5645349c8fb32402769330",
      "40637fac673f434cb008916fc7b41c77",
      "e5b34391c7b0464da18d89244f90ffa3",
      "f4792f69a1234a86923e1c86da74252b",
      "ae96f667aec64e8ea3a6340070ee5cb3",
      "4a1e641c371e4aef8ac4a9366390467d",
      "e98dda48aed44b4c9ade7565a6b3e3fe"
     ]
    },
    "id": "HsQw6SZu9WFY",
    "outputId": "6ba40009-affe-47d9-b75b-344448aefd7a"
   },
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "\n",
    "# remove diacritic\n",
    "def remove_diacritic(example):\n",
    "    example['transcription'] = araby.strip_diacritics(example['transcription'])\n",
    "    return example\n",
    "\n",
    "dataset['train'] = dataset['train'].map(remove_diacritic)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUXd558J-XXG",
    "outputId": "2c76cf9f-8441-48ac-b363-e4ba425a0f9b"
   },
   "outputs": [],
   "source": [
    "filtered_dataset2 = filter_dataset_2(dataset['train'])\n",
    "\n",
    "print(filtered_dataset2)\n",
    "\n",
    "for i in range(len(filtered_dataset2)):\n",
    "  print(filtered_dataset2[i]['audio']['path'])\n",
    "  print(filtered_dataset2[i]['transcription'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhBozeUSDKif",
    "outputId": "cab9aae9-4939-469e-82c4-85bfcff2e78b"
   },
   "outputs": [],
   "source": [
    "# split the dataset for testing n validation\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcQQ1_xKDK_4",
    "outputId": "f54b8525-7f69-4536-c66e-6bce5c11c3a7"
   },
   "outputs": [],
   "source": [
    "my_dataset_test = dataset['test'].train_test_split(test_size=0.5)\n",
    "print(my_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6ULYdNgDN8E",
    "outputId": "d5d16100-0a3d-4b91-f3fe-db2c8fae3171"
   },
   "outputs": [],
   "source": [
    "dataset['validation'] = my_dataset_test['train']\n",
    "dataset['test'] = my_dataset_test['test']\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zdJydyA-LgK"
   },
   "outputs": [],
   "source": [
    "# this is not giving eng chars or all arabic chars in the vocab\n",
    "\n",
    "# def extract_all_chars(batch):\n",
    "#     all_texts = [\" \".join(text) for text in batch[\"transcription\"]]\n",
    "#     print(all_texts)\n",
    "#     vocab_list = [list(set(text)) for text in all_texts]\n",
    "#     print(vocab_list)\n",
    "#     return {\n",
    "#         \"vocab\": vocab_list,\n",
    "#         \"all_text\": all_texts\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWTYaDZpF28M"
   },
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"transcription\"])\n",
    "  print(all_text)\n",
    "  vocab = list(set(all_text))\n",
    "  print(vocab)\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "de520e0c7c78488f9f2d0b34a7f8d71d",
      "32bf5dadcb7e4b0991bb23624b1979f4",
      "0f4370a704d94c72a48432b1c7418604",
      "d7ef2efcd7f94a65af01b8453a0a97e5",
      "208dc0ed0f464b458303df74347ae5e7",
      "fd37fcb389624d7e84f74097511b6c68",
      "670ad9a0731d498bb694e42e85f02dd9",
      "cfb54c29ee0949948ee438c504f53530",
      "9884ba92483a4f2e9a6a2424f9378db5",
      "390bcc488d334f42ad6307ffbb75cb02",
      "f554b6d597544ca696288b4ffe4582a6",
      "d78025ce09304a5f9daa347da5a2235a",
      "26e051d93995483abef0e444a99386c7",
      "faa19826922b40efbf52203ae2bde009",
      "d5ce7171bac94b9da266fd4e91b9396c",
      "76dd446f79634f58b1251193e04d592b",
      "a11b103da5f24048ad2b13939f1c10ff",
      "481e21bbf8654552b6dc55d22a983f60",
      "87bfbed6b7894da2a697ecc9bfbbdb85",
      "a3110fcf27d143feb1c6d0694526d7bd",
      "a9faca2b61244db8893e73021e025fe7",
      "9ddc0e167a21406ea38d797e95207b21",
      "c576ac9f3077464796a0ac333259bd4c",
      "a25fb417440f4e1499f92b595599d621",
      "1282bc52f1ef46cfb028247274947b63",
      "9acd48bff72249deb0099dcef7d045c3",
      "36506850cb3148bf90a47983520aa4c4",
      "a14db919e0a0441f91f3f5131f9e6df1",
      "c66d37b043cb4bb9b4bfebb0e5ad4ca4",
      "6db12257d4f448bdb3818e2e4cf51734",
      "23e04bd302784e81879bd004e56b61bf",
      "c1aa2aadff9045139a6166a71fea4ba9",
      "12468582e2e043589b3898c23eaf46a2"
     ]
    },
    "id": "tqWEYrtBNiAW",
    "outputId": "442ba514-37e7-4a19-c6d7-a1e84bc001cf"
   },
   "outputs": [],
   "source": [
    "vocab_train = dataset['train'].map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataset['train'].column_names)\n",
    "vocab_val = dataset['validation'].map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataset['validation'].column_names)\n",
    "vocab_test = dataset['test'].map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataset['test'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2kenQtGH7-8"
   },
   "outputs": [],
   "source": [
    "# all distinct letters in the training dataset and test dataset\n",
    "\n",
    "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0])| set(vocab_val[\"vocab\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tjlI8xMPHh0",
    "outputId": "558862a2-aa67-4a7c-b97e-faa7675704dc"
   },
   "outputs": [],
   "source": [
    "print(len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wp78OozunH0",
    "outputId": "75faf87c-6ddb-4e80-d171-b4bee322bedb"
   },
   "outputs": [],
   "source": [
    "print((vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18PaGi9DV84V"
   },
   "outputs": [],
   "source": [
    "vocab_list.append('q')\n",
    "vocab_list.append('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzpwlxUnH_Ag",
    "outputId": "3ef9d932-b70d-48f7-a970-b61421248ca9"
   },
   "outputs": [],
   "source": [
    "vocab_dict = {k:v for k, v in enumerate(sorted(vocab_list))}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyLHCMLaOiZF",
    "outputId": "19abf28e-5382-4faf-fda3-a31c7a7693fd"
   },
   "outputs": [],
   "source": [
    "vocab_dict2 = {}\n",
    "for k, v in vocab_dict.items():\n",
    "  vocab_dict2[v] = k\n",
    "print(vocab_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bSVLZ-zIhif"
   },
   "outputs": [],
   "source": [
    "# let space be | and remove new line\n",
    "\n",
    "vocab_dict = vocab_dict2\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "del vocab_dict[\"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O34w7QCI_2p4",
    "outputId": "f007063c-7cbf-481a-e660-beb21b26eecd"
   },
   "outputs": [],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41WsxPuh__zT",
    "outputId": "2989cdef-06fc-408f-b407-93a52cf1571a"
   },
   "outputs": [],
   "source": [
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M76KlJjiJPJu",
    "outputId": "17aabe8b-c3bb-4b32-d25f-84efe7d0f22b"
   },
   "outputs": [],
   "source": [
    "# add unk and padding tokens\n",
    "\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict) + 1 # plus one because the last char already has len as value\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict) + 1\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnHPgQmYOqGb",
    "outputId": "0000869b-9111-4389-ca82-08e45ebd949c"
   },
   "outputs": [],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PC4G8OAuJccn"
   },
   "outputs": [],
   "source": [
    "# save the vocab\n",
    "\n",
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPmVpxATJgj6"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"./\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\") # load vocab to the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqMjWMptR8AI"
   },
   "outputs": [],
   "source": [
    "repo_name = \"wav2vec2-arabic-colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "ddce6cf616fa43b780b991dd22c75d0e",
      "9b8980eb83784299afd9758d087bc360",
      "8b89247258b2462cbd8b01fa3780d0fc",
      "27b04da4c46a4f0386de7433563dc8f1",
      "7bcbe61da209444385d99c3ff0f0e2d1",
      "e76d8e21fd7c452e88c4a759d98e28ad",
      "4060fa1fb5bd49049c0c965f2d0def48",
      "8310fcf5c4d04564a1ee24a45eaa22b2",
      "3a05f416fb384e3bb7a5b66de5a94e9e",
      "683a143a393a4bcf86319d08421728d7",
      "4f968ad7bbcc438aa6704bcad8e8689f"
     ]
    },
    "id": "0kZPA70JSBkM",
    "outputId": "b5c9083e-6eb0-4c39-da7c-4efe9397d7e5"
   },
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIleC7Ko_7x_",
    "outputId": "d7d7a878-ff84-4be1-b1af-9a03b687e19f"
   },
   "outputs": [],
   "source": [
    "input_str = filtered_dataset2[0][\"transcription\"]\n",
    "labels = tokenizer(input_str).input_ids # it returns a dict of input ids and attention mask so just get the input ids\n",
    "print(labels)\n",
    "print(tokenizer.tokenize(input_str))\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True, group_tokens=False)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT33ozq5J0fH"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_Uh1VYTKAAQ"
   },
   "outputs": [],
   "source": [
    "# the feature extractor and tokenizer are wrapped into a single Wav2Vec2Processor class so that one only needs a model and processor object\n",
    "\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ot6sGhnTKJtF",
    "outputId": "a01419a7-9d7c-4c77-91fd-6b7f63bb6b8c"
   },
   "outputs": [],
   "source": [
    "# check the sampling rate\n",
    "\n",
    "dataset['train'][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mv4wMkhKKYC1"
   },
   "outputs": [],
   "source": [
    "# set the audio feature to the correct sampling rate\n",
    "\n",
    "from datasets import Audio\n",
    "\n",
    "dataset['train'] = dataset['train'].cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "dataset['validation'] = dataset['validation'].cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epBoXha1LRxP",
    "outputId": "c8054529-f4b2-41ad-cb21-8abac44ccd94"
   },
   "outputs": [],
   "source": [
    "dataset['train'][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "Y354etU-LiSn",
    "outputId": "ace16e33-4853-44f1-d378-2873ad805424"
   },
   "outputs": [],
   "source": [
    "#check that the data is correctly prepared\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(dataset['train'])-1)\n",
    "\n",
    "print(dataset['train'][rand_int][\"transcription\"])\n",
    "ipd.Audio(data=dataset['train'][rand_int][\"audio\"][\"array\"], autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rv00jI4PL9yg",
    "outputId": "60298359-add2-441d-a8ce-8e1efdf3df58"
   },
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(dataset['train'])-1)\n",
    "\n",
    "print(\"Target text:\", dataset['train'][rand_int][\"transcription\"])\n",
    "print(\"Input array shape:\", dataset['train'][rand_int][\"audio\"][\"array\"].shape)\n",
    "print(\"Sampling rate:\", dataset['train'][rand_int][\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPASZ8L2M7wr"
   },
   "outputs": [],
   "source": [
    "#apply the data preparation function to all examples\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"transcription\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "25390e41f52e4667b014613adf4b485d",
      "5e6f624d969c4e9597ac6e06c0aed85b",
      "6c39e917df644969a3a5c01e055ca6b7",
      "918f429e99764793ae365c6bf0386ad1",
      "9c67a68940a348c2928c40eef15bb7a1",
      "1191c86bd97a412caf7c342610f245ae",
      "80d5caa2d6f5480d827343660eed8205",
      "b3894818138e440eaa9098f6fa19c2c2",
      "49bdb090df004ff9996d363e0d9b4d1c",
      "af063492c2b043259f036d2ebab47c6a",
      "6ba68245158f49aea806f481da686f03",
      "34a351a4dc6b46cd8bf24fc6d9bc3296",
      "a5730be0cb424a3f9de5595c78a9ccc9",
      "7b5c3c826bca46db91f841ce74f488d2",
      "1fda0c887a304a0eb7235a6315291c53",
      "d6ecb314b2a14c81a5fa055a30785405",
      "39c722c58b6f402990727bb1f856ec75",
      "7e2aa089f78443de9cfa420c7696f705",
      "bfa30c5cad9e4ef88442caef20cbf6e5",
      "15f9064c431c42668fae663954014f9e",
      "340c0570382449c49373d50e02d31e52",
      "8f98a8f99ce04e72b9d07d4e2897e019"
     ]
    },
    "id": "uj_dD4P2NGVe",
    "outputId": "7dec066d-cc72-4e35-dbd1-dc67970be6f3"
   },
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].map(prepare_dataset, remove_columns=dataset['train'].column_names)\n",
    "dataset['validation'] = dataset['validation'].map(prepare_dataset, remove_columns=dataset['validation'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tborvC9hx88e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1B1fk34Qd5O"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "af020eca58de433bad3cdbd77a6ab67e",
      "6d98d54c27434627ba4db07cbf1ee4bf",
      "d89fbe8f3dd2495088b6de3a2f28563a",
      "876985b4b49345ed8ae8a46ef7611e0a",
      "6a7bdefb14b24d7197c10bcc0d995515",
      "d3bcd78532654ccc87c9a9b4c9d9bac8",
      "207a4528ec5445b68e60a83b51bf0c35",
      "f06d4fc4bf0f488a990a0d9a419a6078",
      "a564bdfc775a4383a29f72c4dd439f6a",
      "ef11912166f841b493f261f5135eee84",
      "90bbb85966344cfab506edab4cd0fe89",
      "ed7ca87180aa4f2aa310b2c34cccdad7",
      "2cfa5c84adf44ebda8fe6f8033c43aab",
      "1fbdac7c2c12470fb568cebbd6be75f7",
      "45aa1fc51a2f4a629bbf93aa576d2c3e",
      "c90922fe87d940ea907e547366f5ac80",
      "7540ae7a18c24f5cbd83e26a0cac82ac",
      "9d53879e9307420e940f175236863c1e",
      "1e701d43389a4d9d8c6c611c1fa42825",
      "7ac76ea281a4449d9a47059d1ff87432",
      "2c26aa80c44d44c0b7643bb54b864bca",
      "a4262012c11a45929eeda3de12dadb5e"
     ]
    },
    "id": "ri_Smv16QlDP",
    "outputId": "f8446989-d51d-45aa-9d87-0d12054ff3e4"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "metric2 = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoP9L6zCQ79S"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    with open('refs_and_preds.txt', 'w') as f:\n",
    "      for ref, pred in zip(label_str, pred_str):\n",
    "          f.write(f\"Ref: {ref}\\n\")\n",
    "          f.write(f\"Pred: {pred}\\n\\n\")\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = 100 * metric2.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\":cer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "648130582bdd450db402fdd521ad15d0",
      "a87fe24401ba4aa198336fc9baebce59",
      "2f79f0b8853c41a4bd67463fcd53db31",
      "d56f4fe8b5ba4f82a1e3abf6c2e7b217",
      "5e6c7702a2024e2396b2676c831f628d",
      "c9c4b7615b684bb0a18cf177d5fdb568",
      "74e1d2e07e734f27ae65404d15853120",
      "853466a8f37b4e2fb484d019d921de3f",
      "7a63f08a7c764184a019f96d9b6e5a10",
      "edc38550d6f3404e994aeb8698ccc725",
      "bb19176da4ac4a7e9d3a5dc3ba9e1655",
      "b7ae118f010c4c94b95cad10f3fcc568",
      "9edba34d9eec47a8b8d11d46f6fe4e02",
      "a6cd37d394984c86ab569206592fa373",
      "a6be499d30f841d7b62c1ed9ef8ea3b6",
      "0f5abce436a7471c886722e5b9c5b827",
      "d24bc4f4570c4fa3b8898f3f3f31e2a6",
      "8418b0f92e544c40825dbb18613c394e",
      "a51f2e93cce74b3a90adc9fd5d06d9d7",
      "4b538ea36232413a9a07d222c9e2ed85",
      "531034a812ec453e94890e33f07eb0c2",
      "b6d29917c65049a3a48d45668abe81a6"
     ]
    },
    "id": "Vkp1FQXvRGfR",
    "outputId": "3812d655-25a6-47d8-fc69-c13c2b8aafed"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-xls-r-300m\",\n",
    "    attention_dropout=0.0, # dropout for attention layers, can try 0.1\n",
    "    hidden_dropout=0.0, # dropout for hidden layers, can try 0.1\n",
    "    feat_proj_dropout=0.0, # dropout for feature projection layers, can try 0.1\n",
    "    mask_time_prob=0.05, # probability to mask time step\n",
    "    layerdrop=0.0, # probability to drop entire transformer layer\n",
    "    ctc_loss_reduction=\"mean\", # avg loss across batch for ctc loss\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "skHE4HW0RRBJ",
    "outputId": "5ae3c824-dd29-4e3f-c0dd-69bc77f8f1a3"
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "Tz2YRbHXRlYr",
    "outputId": "6de79038-608c-42ab-d9e9-40b03e81487d"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=repo_name,\n",
    "  group_by_length=True, # to prevent excess padding\n",
    "  per_device_train_batch_size=2, # changed it as out of memory error\n",
    "  gradient_accumulation_steps=8,\n",
    "  per_device_eval_batch_size=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  # num_train_epochs=30,\n",
    "  max_steps=1000,\n",
    "  gradient_checkpointing=True,\n",
    "  fp16=True,\n",
    "  save_steps=200,\n",
    "  eval_steps=200,\n",
    "  logging_steps=200,\n",
    "  learning_rate=3e-4,\n",
    "  # warmup_steps=500,\n",
    "  warmup_steps=100,\n",
    "  push_to_hub=True,\n",
    "  report_to=[\"tensorboard\"],\n",
    "  # param like whisper\n",
    "  predict_with_generate=True,\n",
    "  generation_max_length=270, # tokens\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"wer\",\n",
    "  greater_is_better=False, # because lower wer is better\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "1rceYvYaXorJ",
    "outputId": "2491347c-59db-43a8-e518-d23ec136f683"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "FwwEf9ubYRqn",
    "outputId": "dadcc60a-fbcb-422e-d9de-8924d5eabbc5"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "CVrJPykdYU3V",
    "outputId": "f064d6d0-6a8b-423c-f9cd-628eebd8e71f"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8joifX7s1r3a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
