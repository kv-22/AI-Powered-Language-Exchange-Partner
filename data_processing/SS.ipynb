{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch pydub openai-whisper accelerate numba syllables librosa torchaudio openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import whisper\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with one audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "#convert to wav format\n",
    "audio = AudioSegment.from_file(\"speechscoring/speech_data/audio onepte-repeat sentence/audio_0a5a69f5-ba7d-4711-b43d-06d71d8cb59d.m4a\")\n",
    "audio.export(\"output.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio=file_path,  word_timestamps=True, language='en') # word_timestamps=True to get timestamps\n",
    "    return result\n",
    "\n",
    "result = transcribe_audio(\"output.wav\")\n",
    "print(\"Transcribed Text:\")\n",
    "print(result[\"text\"])\n",
    "print(result['segments'])\n",
    "\n",
    "#print timestamps\n",
    "for segment in result['segments']:\n",
    "    print(''.join(f\"{word['word']}[{word['start']}/{word['end']}]\" \n",
    "                    for word in segment['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_output = result['segments']\n",
    "whisper_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pause threshold\n",
    "pause_threshold = 0.25\n",
    "\n",
    "whisper_output = result['segments'][0]['words']\n",
    "\n",
    "# Detect pauses\n",
    "pauses = []\n",
    "for i in range(1, len(whisper_output)):\n",
    "    prev_word_end = whisper_output[i-1][\"end\"]\n",
    "    curr_word_start = whisper_output[i][\"start\"]\n",
    "    pause_duration = curr_word_start - prev_word_end\n",
    "\n",
    "    if pause_duration > pause_threshold:\n",
    "        pauses.append({\n",
    "            \"start\": prev_word_end,\n",
    "            \"end\": curr_word_start,\n",
    "            \"duration\": pause_duration\n",
    "        })\n",
    "\n",
    "for pause in pauses:\n",
    "    print(f\"Pause from {pause['start']:.2f}s to {pause['end']:.2f}s (duration: {pause['duration']:.2f}s)\")\n",
    "\n",
    "# Calculate total pause duration and frequency\n",
    "total_pause_duration = sum(pause[\"duration\"] for pause in pauses)\n",
    "pause_frequency = len(pauses)\n",
    "\n",
    "print(\"\\nTotal pause duration:\", total_pause_duration)\n",
    "print(\"Pause frequency:\", pause_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count syllables (requires a syllable counter)\n",
    "from syllables import estimate\n",
    "\n",
    "syllable_count = estimate(result['text'])\n",
    "\n",
    "# Calculate total duration (including pauses)\n",
    "total_duration = whisper_output[-1][\"end\"]\n",
    "\n",
    "# Calculate speaking duration (excluding pauses)\n",
    "speaking_duration = total_duration - total_pause_duration\n",
    "\n",
    "# Calculate speech rate and articulation rate\n",
    "speech_rate = syllable_count / total_duration\n",
    "articulation_rate = syllable_count / speaking_duration\n",
    "\n",
    "# Calculate average pause duration\n",
    "average_pause_duration = total_pause_duration / pause_frequency if pause_frequency > 0 else 0\n",
    "\n",
    "# Calculate phonation time ratio\n",
    "phonation_time_ratio = speaking_duration / total_duration # not sure if this is same as the formula exactly \n",
    "\n",
    "print(\"\\nFluency Features:\")\n",
    "print(\"Speech Rate:\", speech_rate)\n",
    "print(\"Articulation Rate:\", articulation_rate)\n",
    "print(\"Average Pause Duration:\", average_pause_duration)\n",
    "print(\"Phonation Time Ratio:\", phonation_time_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load audio file\n",
    "audio_path = \"output.wav\"\n",
    "y, sr = librosa.load(audio_path, sr=16000)  # y: audio signal, sr: sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y)\n",
    "plt.title('Waveform of the Audio Signal')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import os\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Define pause threshold\n",
    "pause_threshold = 0.25\n",
    "\n",
    "# Function to extract features from audio\n",
    "def extract_features(audio_path):\n",
    "    # Automatically detect format based on file extension\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    audio.export(\"temp.wav\", format=\"wav\")\n",
    "\n",
    "    # Transcribe audio\n",
    "    result = model.transcribe(audio=\"temp.wav\", word_timestamps=True)\n",
    "    whisper_output = result['segments'][0]['words']\n",
    "\n",
    "    # Detect pauses\n",
    "    pauses = []\n",
    "    for i in range(1, len(whisper_output)):\n",
    "        prev_word_end = whisper_output[i-1][\"end\"]\n",
    "        curr_word_start = whisper_output[i][\"start\"]\n",
    "        pause_duration = curr_word_start - prev_word_end\n",
    "\n",
    "        if pause_duration > pause_threshold:\n",
    "            pauses.append({\n",
    "                \"start\": prev_word_end,\n",
    "                \"end\": curr_word_start,\n",
    "                \"duration\": pause_duration\n",
    "            })\n",
    "\n",
    "    # Calculate total pause duration and frequency\n",
    "    total_pause_duration = sum(pause[\"duration\"] for pause in pauses)\n",
    "    pause_frequency = len(pauses)\n",
    "\n",
    "    # Count syllables\n",
    "    syllable_count = estimate(result['text'])\n",
    "\n",
    "    # Calculate total duration (including pauses)\n",
    "    total_duration = whisper_output[-1][\"end\"]\n",
    "\n",
    "    # Calculate speaking duration (excluding pauses)\n",
    "    speaking_duration = total_duration - total_pause_duration\n",
    "\n",
    "    # Calculate features\n",
    "    speech_rate = syllable_count / total_duration\n",
    "    articulation_rate = syllable_count / speaking_duration\n",
    "    average_pause_duration = total_pause_duration / pause_frequency if pause_frequency > 0 else 0\n",
    "    phonation_time_ratio = speaking_duration / total_duration\n",
    "\n",
    "    # Return features as a dictionary\n",
    "    return {\n",
    "        \"speech_rate\": speech_rate,\n",
    "        \"articulation_rate\": articulation_rate,\n",
    "        \"average_pause_duration\": average_pause_duration,\n",
    "        \"phonation_time_ratio\": phonation_time_ratio\n",
    "    }\n",
    "\n",
    "# Path to the directory containing audio files\n",
    "audio_dir = \"speechscoring/speech_data/audio onepte-repeat sentence\"\n",
    "\n",
    "# Load existing Excel file\n",
    "input_excel_path = \"speechscoring/processed_audio_sample_scoring.xlsx\"  \n",
    "wb = openpyxl.load_workbook(input_excel_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Find the last row with data\n",
    "last_row = ws.max_row\n",
    "\n",
    "# Add headers for new columns if they don't exist\n",
    "if \"Speech Rate\" not in [cell.value for cell in ws[1]]:\n",
    "    ws.cell(row=1, column=ws.max_column + 1, value=\"Speech Rate\")\n",
    "    ws.cell(row=1, column=ws.max_column + 1, value=\"Articulation Rate\")\n",
    "    ws.cell(row=1, column=ws.max_column + 1, value=\"Average Pause Duration\")\n",
    "    ws.cell(row=1, column=ws.max_column + 1, value=\"Phonation Time Ratio\")\n",
    "\n",
    "# Iterate through audio files\n",
    "for file_name in os.listdir(audio_dir):\n",
    "    if file_name.endswith(\".m4a\") or file_name.endswith(\".mp3\"):\n",
    "        file_path = os.path.join(audio_dir, file_name)\n",
    "        print(f\"Processing {file_name}...\")\n",
    "\n",
    "        # Extract features\n",
    "        features = extract_features(file_path)\n",
    "\n",
    "        # Remove file extension for matching\n",
    "        file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # Find the row corresponding to the current file\n",
    "        for row in ws.iter_rows(min_row=2, max_row=last_row, min_col=1, max_col=2):\n",
    "            if row[1].value == file_name_without_extension:\n",
    "                # Write features to the corresponding row\n",
    "                ws.cell(row=row[1].row, column=ws.max_column - 3, value=features[\"speech_rate\"])\n",
    "                ws.cell(row=row[1].row, column=ws.max_column - 2, value=features[\"articulation_rate\"])\n",
    "                ws.cell(row=row[1].row, column=ws.max_column - 1, value=features[\"average_pause_duration\"])\n",
    "                ws.cell(row=row[1].row, column=ws.max_column, value=features[\"phonation_time_ratio\"])\n",
    "                break\n",
    "\n",
    "# Save the updated Excel file\n",
    "output_excel_path = \"updated_speech_features.xlsx\"\n",
    "wb.save(output_excel_path)\n",
    "print(f\"Features saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ptmetal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
